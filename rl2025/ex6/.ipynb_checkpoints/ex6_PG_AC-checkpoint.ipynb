{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8323a86e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "968ecb4cb3b8623792cd5938edc4ea1b",
     "grade": false,
     "grade_id": "cell-47bfc0ea1447f571",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "   <h2 align=\"center\"> <center><b> Reinforcement Learning Assignment 6 - Actor Critic part 1 </b></center></h2>\n",
    "\n",
    "<br>\n",
    "<center><font size=\"3\">This notebook is part of the teaching material for ELEC-E8125</font></center>\n",
    "<center><font size=\"3\">Aalto University</font></center>\n",
    "</div>\n",
    "\n",
    "\n",
    "<a id='TOC'></a>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "# Table of contents\n",
    "* <a href='#1.'> 1. Introduction </a>\n",
    "* <a href='#1.1'> 1.1 Learning Objectives </a>\n",
    "* <a href='#1.2'> 1.2 Code Structure & Files </a>\n",
    "* <a href='#2.'> 2. Policy Gradient with a Critic </a>\n",
    "* <a href='#3.'> 3. Submitting </a>\n",
    "* <a href='#3.1'> 3.1 Feedback </a>\n",
    "* <a href='#4.'> References</a>\n",
    "\n",
    "<a href='#T1'><b>Student Task 1.</b> Implementing PG with critic (20 points)</a>\\\n",
    "<a href='#Q1'><b>Student Question 1.1</b> Relationship between actor-critic and REINFORCE with baseline (10 points)</a>\\\n",
    "<a href='#Q2'><b>Student Question 1.2</b> Advantage (5 points)  </a>\\\n",
    "<a href='#Q3'><b>Student Question 1.3</b> Bias and Variance Analysis (10 points) </a>\\\n",
    "<a href='#Q4'><b>Student Question 1.4</b> Controlling bias-variance tradeoff (10 points)</a>\n",
    "    \n",
    "**Total Points:** 55\n",
    "\n",
    "**Estimated runtime of all the cells:** 1 hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab53631b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a4ce01f58b207f5715f395b180619b9e",
     "grade": false,
     "grade_id": "cell-6ef87fd4c2d2cc44",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 1. Introduction <a id='1.'></a>\n",
    "\n",
    "In this assignment, we will implement an actor-critic reinforcement learning algorithm which combines elements of both value-based methods (critic) and policy-based methods (actor) to improve learning and stability in the **InvertedPendulum-v4**  environment.\n",
    "\n",
    "## 1.1 Task environments: <a id='1.1'></a>\n",
    "\n",
    "In this exercise, we will focus on InvertedPendulum-v4 tasks:\n",
    "- InvertedPendulum-v4(https://gymnasium.farama.org/environments/mujoco/inverted_pendulum/): This environment is similar to the cartpole environment but now powered by the Mujoco physics simulator - allowing for more complex experiments (such as varying the effects of gravity). This environment involves a cart that moves horizontally, with a pole fixed on the cart at one end and the other end of the pole moving freely. The cart can be pushed left or right. The goal is to move the pole such that it is vertically above the cart pointing straight up by applying horizontal forces on the cart.\n",
    "<figure style=\"text-align: center\">\n",
    "    <img src=\"imgs/InvertedPendulum.png\" width=\"300\"/>\n",
    "    <figcaption style=\"text-align: center\">  Figure 1: The InvertedPendulum-v4 environment. </figcaption>\n",
    "</figure>\n",
    "\n",
    "## 1.2 Learning Objectives: <a id='1.1'></a>\n",
    "\n",
    "- Understand the idea of actor-critic algorithms\n",
    "- Understand the limits and use cases of actor-critics\n",
    "\n",
    "## 1.3 Code Structure & Files <a id='1.2'></a>\n",
    "\n",
    "```ex6_PG_AC.ipynb``` is the file needed to be modified for this part of the assignment.  \n",
    "\n",
    "<span style=\"color:red\"> **# IMPORTANT: DO NOT FORGET ANOTHER PART IN ```ex6_DDPG.ipynb```** </span>\n",
    "\n",
    "```\n",
    "‚îú‚îÄ‚îÄ‚îÄcfg                            # Config files for environments\n",
    "‚îú‚îÄ‚îÄ‚îÄimgs                           # Images used in notebook\n",
    "‚îú‚îÄ‚îÄ‚îÄresults\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ‚îÄHalfCheetah-v4\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ‚îÄlogging                \n",
    "‚îÇ   ‚îÇ   ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄlogging.pkl        # Contains logged data\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ‚îÄmodel              \n",
    "‚îÇ   ‚îÇ   ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ*HalfCheetah-v4_params.pt    # Contains trained model\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄvideo                   # Videos saved\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ*ddpg.png               # Contains training performance plot\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ‚îÄInvertedPendulum-v4\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ‚îÄlogging                \n",
    "‚îÇ   ‚îÇ   ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄlogging.pkl        # Contains logged data\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ‚îÄmodel              \n",
    "‚îÇ   ‚îÇ   ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ*InvertedPendulum-v4_params.pt      # Contains trained model\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄvideo                   # Videos saved\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ*pg_ac.png              # Contains training performance plot\n",
    "‚îÇ   ex6_DDPG.ipynb                  # 2nd assignment file containing tasks <---------\n",
    "‚îÇ   ex6_PG_AC.ipynb                 # 1st assignment file containing tasks <---------This task\n",
    "‚îÇ   train.py                        # Contains train and test functions \n",
    "‚îÇ   utils.py                        # Contains useful functions \n",
    "‚îî‚îÄ‚îÄ‚îÄbuffer.py                       # Contains buffer functions\n",
    "```\n",
    "\n",
    "## 1.4 Execution time <a id='1.4'></a>\n",
    "\n",
    "The training of Actor-Critic may take more than 30 mins depending on the server load. If you have problems with the training time, you can train locally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ef1c90",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e2a4fdb4406c82cbf0924a4ae9fd56ca",
     "grade": false,
     "grade_id": "cell-76eb1e3dcf217198",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Warnings:\n",
    "\n",
    "- Don‚Äôt copy and paste cells within a notebook. This will mess up the tracking metadata and prevent autograding from working.\n",
    "- Only add new cells using the '+' button in the upper toolbar and do not split cells.\n",
    "- Be cautious about things such as copying the whole notebook to Colab to work on it. This has sometimes resulted in removing all notebook metadata, making autograding impossible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb79df48",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dd4a8717cd49c894ce9a4aa3a1895148",
     "grade": false,
     "grade_id": "cell-78fdf22a73920722",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "# 2. Policy Gradient with a Critic <a id='2.'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c584d11d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0439bebaa3d0d286f254868ab55e9939",
     "grade": false,
     "grade_id": "cell-61899a5dd880417b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='T1'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <h3><b>Student Task 1.</b> Implement policy gradient (PG) with critic (20 points) </h3> \n",
    "\n",
    "Revisit the policy gradient solution for the InvertedPendulum from Exercise 5 with learned sigma if needed. Implement the actor-critic algorithm below. Perform TD(0) updates at the end of each episode. You can check the training performance plot in the result folder after running the plot cell. Take Figure 2 as a reference training plot. \n",
    "    \n",
    "**Hint:** Check out the PyTorch tutorial from [here](https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html) to see how to calculate the $A_\\theta \\Delta_\\theta \\log \\pi_\\theta(a_i|s_i)$ term using the ```detach()``` function. \n",
    "\n",
    "<figure style=\"text-align: center\">\n",
    "<img src=\"imgs/pg_ac.png\" width=\"400px\">\n",
    "<figcaption style=\"text-align: center\"> Figure 2: Training plot of the policy gradient with a critic.\n",
    "</figcaption>\n",
    "</figure>\n",
    "     \n",
    "**Complete the all the unfinished implementation in `PG` class (marked with ```TODOs```)**. \n",
    "    \n",
    "1. **Policy Network**: Finish the `__init__(self, state_dim, action_dim)` function and `forward(self, state)` function within the `Policy` class\n",
    "2. **Agent Update Function**: Finish the `update(self, )` function within the `PG` class\n",
    "3. **Get Action Method**: Finish the `get_action(self, observation, evaluation=False)` function within the `PG` class.\n",
    "    \n",
    "üîù\t<a href='#TOC'><b>Table of Contents</b></a>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9dc0d42e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "skip_training = True  # Set this flag to True before validation and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489df71f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e4a46183e22c508d922baebfefbe6a0a",
     "grade": true,
     "grade_id": "cell-f54b5f40d174d5b2",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fad4384f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from IPython.display import Video\n",
    "\n",
    "import torch, yaml\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "\n",
    "import train as t\n",
    "import utils as u\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a6634d41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Actor-critic agent\n",
    "def layer_init(layer, std=np.sqrt(2), bias_const=0.0):\n",
    "    torch.nn.init.orthogonal_(layer.weight, std)\n",
    "    torch.nn.init.constant_(layer.bias, bias_const)\n",
    "    return layer\n",
    "\n",
    "\n",
    "class Policy(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super().__init__()\n",
    "        # Create a neural network and use it for the mean of the policy.\n",
    "        # The size of the neural network here has been chosen such that \n",
    "        # it is not too big but should perform well in the tasks we want to look at.\n",
    "        self.actor_mean = nn.Sequential(\n",
    "            layer_init(nn.Linear(state_dim, 64)), nn.Tanh(),\n",
    "            layer_init(nn.Linear(64, 64)), nn.Tanh(),\n",
    "            layer_init(nn.Linear(64, action_dim), std=0.01),\n",
    "        )\n",
    "        \n",
    "        \"\"\"\n",
    "        # TODO: Implement actor_logstd as a learnable parameter\n",
    "        # Use log of std to make sure std (standard deviation) of the policy\n",
    "        # doesn't become negative during training\n",
    "        \"\"\"\n",
    "        #self.actor_logstd = ...\n",
    "        self.actor_logstd = nn.Parameter(torch.zeros(1, action_dim))\n",
    "        \n",
    "    def forward(self, state):\n",
    "        # Get mean of a Normal distribution (the output of the neural network)\n",
    "        action_mean = self.actor_mean(state)\n",
    "\n",
    "        # Make sure action_logstd matches dimensions of action_mean\n",
    "        action_logstd = self.actor_logstd.expand_as(action_mean)\n",
    "\n",
    "        # Exponentiate the log std to get actual std\n",
    "        action_std = torch.exp(action_logstd)\n",
    "        \n",
    "        \"\"\"\n",
    "        # TODO: Create a Normal distribution with mean of 'action_mean' & standard deviation of 'action_logstd' \n",
    "        # and return the distribution. You should be using the torch.distributions.Normal class to create the distribution.\n",
    "        \"\"\"\n",
    "        #probs = ...\n",
    "        probs = Normal(action_mean, action_std)\n",
    "\n",
    "        return probs\n",
    "\n",
    "    \n",
    "class Value(nn.Module):\n",
    "    def __init__(self, state_dim):\n",
    "        super().__init__()\n",
    "        self.value = nn.Sequential(\n",
    "            layer_init(nn.Linear(state_dim, 64)), nn.Tanh(),\n",
    "            layer_init(nn.Linear(64, 64)), nn.Tanh(),\n",
    "            layer_init(nn.Linear(64, 1)))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.value(x).squeeze(1) # output shape [batch,]\n",
    "\n",
    "\n",
    "class PG(object):\n",
    "    def __init__(self, state_dim, action_dim, lr, gamma):\n",
    "        self.name = 'pg'\n",
    "        self.policy = Policy(state_dim, action_dim).to(device)\n",
    "        self.value = Value(state_dim).to(device)\n",
    "        self.optimizer = torch.optim.Adam(list(self.policy.parameters()) + list(self.value.parameters()), \n",
    "                                         lr=float(lr),)\n",
    "\n",
    "        self.gamma = gamma\n",
    "\n",
    "        # a simple buffer\n",
    "        self.states = []\n",
    "        self.action_probs = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n",
    "        self.next_states = []\n",
    "\n",
    "    '''\n",
    "    TODO: Task 1\n",
    "    # Complete the following 4 functions\n",
    "    # Hints: 1. calculate the target values as well as the MSE loss between the predicted value and the target values\n",
    "    #        2. calculate the policy loss (similar to ex5) with advantage calculated from the value function. Normalise\n",
    "    #           the advantage to zero mean and unit variance.\n",
    "    #        3. Use mean to calculate the actor (policy) loss ;)\n",
    "    #           - https://discuss.pytorch.org/t/loss-reduction-sum-vs-mean-when-to-use-each/115641/2\n",
    "    '''\n",
    "    \n",
    "    # 1. Calculate the target values, you should not modify the gradient of the variables\n",
    "    def calculate_target_values(self, rewards, next_states, dones):\n",
    "        ########## Your code starts here. ##########\n",
    "        with torch.no_grad():\n",
    "            #next_values = ...\n",
    "            #target_values = ...\n",
    "            next_values = self.value(next_states)\n",
    "            target_values = rewards + self.gamma * (1.0 - dones) * next_values\n",
    "        ########## Your code ends here. ##########\n",
    "        return target_values\n",
    "\n",
    "    # 2. Calculate the critic loss\n",
    "    def calculate_critic_loss(self, values, target_values):\n",
    "        ########## Your code starts here. ##########\n",
    "        #critic_loss = ...\n",
    "        critic_loss = F.mse_loss(values, target_values)\n",
    "        ########## Your code ends here. ##########\n",
    "        return critic_loss\n",
    "    \n",
    "    # 3. Advantage estimation, you should not modify the gradient of the variables\n",
    "    def calculate_advantage(self, values, target_values):\n",
    "        ########## Your code starts here. ##########\n",
    "        with torch.no_grad():\n",
    "            #advantage = ...\n",
    "            advantage = target_values - values\n",
    "            advantage = (advantage - advantage.mean())/(advantage.std() + 1e-9)\n",
    "        ########## Your code ends here. ##########\n",
    "        return advantage\n",
    "    \n",
    "    # 4. Calculate the actor (policy) loss \n",
    "    def calculate_actor_loss(self, action_probs, advantage):\n",
    "        ########## Your code starts here. ##########\n",
    "        #weighted_probs = ...\n",
    "        #actor_loss = ...\n",
    "        weighted_probs = -action_probs*advantage\n",
    "        actor_loss = weighted_probs.mean()\n",
    "        ########## Your code ends here. ##########\n",
    "        return actor_loss\n",
    "\n",
    "    def update(self,):\n",
    "        action_probs = torch.stack(self.action_probs, dim=0) \\\n",
    "                .to(device).squeeze(-1)\n",
    "        rewards = torch.stack(self.rewards, dim=0).to(device).squeeze(-1)\n",
    "        states = torch.stack(self.states, dim=0).to(device).squeeze(-1)\n",
    "        next_states = torch.stack(self.next_states, dim=0).to(device).squeeze(-1)\n",
    "        dones = torch.stack(self.dones, dim=0).to(device).squeeze(-1)\n",
    "        # clear buffer\n",
    "        self.states, self.action_probs, self.rewards, self.dones, self.next_states = [], [], [], [], []\n",
    "\n",
    "        \"\"\"\n",
    "        # TODO: Compute the current state value estimates using the value function network\n",
    "        \"\"\"\n",
    "        #values = ...\n",
    "        values = self.value(states)\n",
    "        \n",
    "        target_values = self.calculate_target_values(rewards, next_states, dones)        \n",
    "        critic_loss = self.calculate_critic_loss(values, target_values)        \n",
    "        advantage = self.calculate_advantage(values, target_values)\n",
    "        actor_loss = self.calculate_actor_loss(action_probs, advantage)\n",
    "\n",
    "        \"\"\"\n",
    "        # TODO: Compute the gradients of the joint loss w.r.t network parameters\n",
    "        \"\"\"\n",
    "        #loss = ...\n",
    "        loss = actor_loss + critic_loss\n",
    "        loss.backward()\n",
    "\n",
    "        # Update network parameters using self.optimizer and zero gradients \n",
    "        self.optimizer.step()  \n",
    "        nn.utils.clip_grad_norm_(list(self.policy.parameters())+ list(self.value.parameters()), 1.0)\n",
    "        self.optimizer.zero_grad() \n",
    "\n",
    "        return {}\n",
    "\n",
    "    def get_action(self, observation, evaluation=False):\n",
    "        \"\"\"Return action (np.ndarray) and logprob (torch.Tensor) of this action.\"\"\"\n",
    "        if observation.ndim == 1: observation = observation[None] # add the batch dimension\n",
    "        x = torch.from_numpy(observation).float().to(device)\n",
    "        \n",
    "        '''\n",
    "        # TODO: Task 1\n",
    "        # Hints: 1. the self.policy returns a normal distribution, check the PyTorch documentation to see \n",
    "        #           how to calculate the log_prob of an action and how to sample.\n",
    "        #        2. if evaluating the policy, return policy mean, otherwise, return a sample\n",
    "        #        3. the returned action and the act_logprob should be torch.Tensors.\n",
    "        #           Please always make sure the shape of variables is as you expected.\n",
    "        '''\n",
    "        ########## Your code starts here. ##########\n",
    "        #dist = ...\n",
    "        #if evaluation:\n",
    "        #    action = ...\n",
    "        #else:\n",
    "        #    action = ...\n",
    "        \n",
    "        dist = self.policy(x)\n",
    "        if evaluation:\n",
    "            action = dist.mean\n",
    "        else:\n",
    "            action = dist.sample()\n",
    "        \n",
    "        # compute the log probability of the action\n",
    "        #act_logprob = ...\n",
    "        act_logprob = dist.log_prob(action)\n",
    "        action = action.squeeze()\n",
    "        \n",
    "        act_logprob = act_logprob.sum(dim=-1)\n",
    "        act_logprob = act_logprob.squeeze()\n",
    "        \n",
    "        ########## Your code ends here. ###########\n",
    "        return action, act_logprob\n",
    "\n",
    "    def record(self, observation, action_prob, next_observation, reward, done):\n",
    "        self.states.append(torch.tensor(observation, dtype=torch.float32))\n",
    "        self.action_probs.append(action_prob)\n",
    "        self.rewards.append(torch.tensor([reward], dtype=torch.float32))\n",
    "        self.dones.append(torch.tensor([done], dtype=torch.float32))\n",
    "        self.next_states.append(torch.tensor(next_observation, dtype=torch.float32))\n",
    "\n",
    "    def load(self, filepath):\n",
    "        d = torch.load(filepath)\n",
    "        self.policy.load_state_dict(d['policy'])\n",
    "        self.value.load_state_dict(d['value'])\n",
    "    \n",
    "    def save(self, filepath):\n",
    "        torch.save({\n",
    "            'policy': self.policy.state_dict(),\n",
    "            'value': self.value.state_dict(),\n",
    "        }, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c970385d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5af7194a025f5c6a09d1e4bd68084daa",
     "grade": true,
     "grade_id": "cell-9122872aaa786a57",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Policy\n",
    "def test_policy_class():\n",
    "    policy = Policy(4, 1)\n",
    "    x = torch.Tensor((1.,2.,3.,4.)).reshape((1,4))\n",
    "    assert isinstance( policy.forward(x),Normal)\n",
    "    assert policy.actor_logstd.requires_grad\n",
    "\n",
    "test_policy_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1267fbc6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8bd467e6ef4d0bce56458aa52ec2b321",
     "grade": true,
     "grade_id": "cell-43cbda8b39fe293e",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy/Torch/Random Seed:  43\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "#Test get_action method\n",
    "def test_get_action_1():\n",
    "    cfg_path=Path().cwd()/'cfg'/'pg_ac.yaml'\n",
    "    cfg_args=dict(save_video=False,testing=False,seed=43)\n",
    "    env, cfg = t.setup(cfg_path, cfg_args=cfg_args)\n",
    "    agent = PG(cfg.state_shape[0], cfg.action_dim, cfg.lr, cfg.gamma)\n",
    "    obs = np.array([ 0.00978977, -0.00972236, -0.00706408,  0.00517535])\n",
    "    action = -2.0871510059805587e-05\n",
    "    assert np.allclose(agent.get_action(obs,True)[0].item(),action,atol=1e-03)\n",
    "\n",
    "    agent2 = PG(cfg.state_shape[0], cfg.action_dim, cfg.lr, cfg.gamma)\n",
    "    assert tuple(agent2.get_action(obs,True)[1].shape) == ()\n",
    "\n",
    "test_get_action_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f1baa5e6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "70ac43e68631b7ae6e31f11b62e2eece",
     "grade": true,
     "grade_id": "cell-5bfa2cf43da8fc00",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy/Torch/Random Seed:  43\n"
     ]
    }
   ],
   "source": [
    "def test_update_function_1():\n",
    "    cfg_path=Path().cwd()/'cfg'/'pg_ac.yaml'\n",
    "    cfg_args=dict(save_video=False,testing=False,seed=43)\n",
    "    env, cfg = t.setup(cfg_path, cfg_args=cfg_args)\n",
    "    agent = PG(4, cfg.action_dim, cfg.lr, cfg.gamma)\n",
    "\n",
    "    rewards = torch.tensor([1., 1., 1., 1.])\n",
    "    action_probs = torch.tensor([-0.9286, -1.1687, -1.2360, -1.7127])\n",
    "    next_states = torch.tensor([[-0.0079,  0.0071, -0.1703,  0.4061],\n",
    "                                [-0.0274,  0.0524, -0.8029,  1.8464],\n",
    "                                [-0.0633,  0.1342, -0.9942,  2.2525],\n",
    "                                [-0.0931,  0.2017, -0.4978,  1.1568]])\n",
    "    dones = torch.tensor([0., 0., 0., 1.])\n",
    "    states = torch.tensor([[-4.6008e-03, -1.0801e-03,  7.1437e-03, -1.4543e-03],\n",
    "                           [-7.8743e-03,  7.0946e-03, -1.7034e-01,  4.0608e-01],\n",
    "                           [-2.7371e-02,  5.2385e-02, -8.0292e-01,  1.8464e+00],\n",
    "                           [-6.3307e-02,  1.3419e-01, -9.9422e-01,  2.2525e+00]])\n",
    "    values = torch.tensor([-0.0013, -0.0137, -0.0187, -0.0289])\n",
    "\n",
    "    target_values = agent.calculate_target_values(rewards, next_states, dones)        \n",
    "    critic_loss = agent.calculate_critic_loss(values, target_values)        \n",
    "    adv = agent.calculate_advantage(values, target_values)\n",
    "    actor_loss = agent.calculate_actor_loss(action_probs, adv)\n",
    "\n",
    "    assert torch.allclose(target_values, torch.tensor([0.9864, 0.9815, 0.9714, 1.0000]), atol = 0.001)\n",
    "    assert torch.allclose(critic_loss, torch.tensor(1.0012), atol = 0.001)\n",
    "    assert torch.allclose(adv, torch.tensor([-0.6645, -0.2767, -0.5391,  1.4803]), atol = 0.001)\n",
    "    assert torch.allclose(actor_loss, torch.tensor(0.2321), atol = 0.001)\n",
    "\n",
    "test_update_function_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "04b263dd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "47065bb40c58f45827cb38b377996854",
     "grade": true,
     "grade_id": "cell-dcf55b2136722f26",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout\n",
    "\"TEST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d39c60f7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c35464679797db9e10ee0bb6646ff6e0",
     "grade": true,
     "grade_id": "cell-289c24f5539ad5d3",
     "locked": true,
     "points": 7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout\n",
    "\"TEST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8c6b02f2-891d-40c1-b01a-9bd370009a3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# init agent\n",
    "with open(Path().cwd()/'cfg'/'pg_ac.yaml', 'r') as f:\n",
    "    cfg = u.Struct(**yaml.safe_load(f))\n",
    "    \n",
    "agent = PG(cfg.state_shape[0], cfg.action_dim, cfg.lr, cfg.gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5fad7389",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy/Torch/Random Seed:  837\n",
      "{'episode': 0, 'timesteps': 5, 'ep_reward': 5.0}\n",
      "{'episode': 50, 'timesteps': 8, 'ep_reward': 8.0}\n",
      "{'episode': 100, 'timesteps': 5, 'ep_reward': 5.0}\n",
      "{'episode': 150, 'timesteps': 10, 'ep_reward': 10.0}\n",
      "{'episode': 200, 'timesteps': 29, 'ep_reward': 29.0}\n",
      "{'episode': 250, 'timesteps': 62, 'ep_reward': 62.0}\n",
      "{'episode': 300, 'timesteps': 62, 'ep_reward': 62.0}\n",
      "{'episode': 350, 'timesteps': 155, 'ep_reward': 155.0}\n",
      "{'episode': 400, 'timesteps': 94, 'ep_reward': 94.0}\n",
      "{'episode': 450, 'timesteps': 44, 'ep_reward': 44.0}\n",
      "{'episode': 500, 'timesteps': 56, 'ep_reward': 56.0}\n",
      "{'episode': 550, 'timesteps': 103, 'ep_reward': 103.0}\n",
      "{'episode': 600, 'timesteps': 145, 'ep_reward': 145.0}\n",
      "{'episode': 650, 'timesteps': 129, 'ep_reward': 129.0}\n",
      "{'episode': 700, 'timesteps': 275, 'ep_reward': 275.0}\n",
      "{'episode': 750, 'timesteps': 310, 'ep_reward': 310.0}\n",
      "{'episode': 800, 'timesteps': 377, 'ep_reward': 377.0}\n",
      "{'episode': 850, 'timesteps': 52, 'ep_reward': 52.0}\n",
      "{'episode': 900, 'timesteps': 233, 'ep_reward': 233.0}\n",
      "{'episode': 950, 'timesteps': 878, 'ep_reward': 878.0}\n",
      "{'episode': 1000, 'timesteps': 575, 'ep_reward': 575.0}\n",
      "{'episode': 1050, 'timesteps': 15, 'ep_reward': 15.0}\n",
      "{'episode': 1100, 'timesteps': 1000, 'ep_reward': 1000.0}\n",
      "{'episode': 1150, 'timesteps': 430, 'ep_reward': 430.0}\n",
      "{'episode': 1200, 'timesteps': 1000, 'ep_reward': 1000.0}\n",
      "{'episode': 1250, 'timesteps': 99, 'ep_reward': 99.0}\n",
      "{'episode': 1300, 'timesteps': 944, 'ep_reward': 944.0}\n",
      "{'episode': 1350, 'timesteps': 751, 'ep_reward': 751.0}\n",
      "{'episode': 1400, 'timesteps': 686, 'ep_reward': 686.0}\n",
      "{'episode': 1450, 'timesteps': 332, 'ep_reward': 332.0}\n",
      "{'episode': 1500, 'timesteps': 1000, 'ep_reward': 1000.0}\n",
      "{'episode': 1550, 'timesteps': 48, 'ep_reward': 48.0}\n",
      "{'episode': 1600, 'timesteps': 11, 'ep_reward': 11.0}\n",
      "{'episode': 1650, 'timesteps': 372, 'ep_reward': 372.0}\n",
      "{'episode': 1700, 'timesteps': 1000, 'ep_reward': 1000.0}\n",
      "{'episode': 1750, 'timesteps': 459, 'ep_reward': 459.0}\n",
      "{'episode': 1800, 'timesteps': 1000, 'ep_reward': 1000.0}\n",
      "{'episode': 1850, 'timesteps': 1000, 'ep_reward': 1000.0}\n",
      "{'episode': 1900, 'timesteps': 27, 'ep_reward': 27.0}\n",
      "{'episode': 1950, 'timesteps': 12, 'ep_reward': 12.0}\n",
      "{'episode': 2000, 'timesteps': 10, 'ep_reward': 10.0}\n",
      "Saving model to /notebooks/rl2025/ex6/results/InvertedPendulum-v4/model/InvertedPendulum-v4_params.pt\n",
      "------ Training Finished ------\n",
      "Total traning time is 5.095177621968712mins\n"
     ]
    }
   ],
   "source": [
    "if not skip_training:\n",
    "    t.train(agent, cfg_path=Path().cwd()/'cfg'/'pg_ac.yaml', cfg_args={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f8041f0c-73f8-4f23-bbd2-4a976a8b842a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy/Torch/Random Seed:  625\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not skip_training:\n",
    "    t.plot(cfg_path=Path().cwd()/'cfg'/'pg_ac.yaml',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "91d4922b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy/Torch/Random Seed:  820\n",
      "Loading model from /notebooks/rl2025/ex6/results/InvertedPendulum-v4/model/InvertedPendulum-v4_params.pt ...\n",
      "Testing ...\n",
      "Moviepy - Building video /notebooks/rl2025/ex6/results/InvertedPendulum-v4/video/test/ex6-episode-0.mp4.\n",
      "Moviepy - Writing video /notebooks/rl2025/ex6/results/InvertedPendulum-v4/video/test/ex6-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /notebooks/rl2025/ex6/results/InvertedPendulum-v4/video/test/ex6-episode-0.mp4\n",
      "Ep0: Test ep_reward is 6.0\n",
      "Ep1: Test ep_reward is 6.0\n",
      "Ep2: Test ep_reward is 6.0\n",
      "Ep3: Test ep_reward is 6.0\n",
      "Ep4: Test ep_reward is 6.0\n",
      "Ep5: Test ep_reward is 6.0\n",
      "Ep6: Test ep_reward is 6.0\n",
      "Ep7: Test ep_reward is 6.0\n",
      "Ep8: Test ep_reward is 6.0\n",
      "Moviepy - Building video /notebooks/rl2025/ex6/results/InvertedPendulum-v4/video/test/ex6-episode-9.mp4.\n",
      "Moviepy - Writing video /notebooks/rl2025/ex6/results/InvertedPendulum-v4/video/test/ex6-episode-9.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /notebooks/rl2025/ex6/results/InvertedPendulum-v4/video/test/ex6-episode-9.mp4\n",
      "Ep9: Test ep_reward is 6.0\n",
      "Average test reward: 6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "if not skip_training:\n",
    "    t.test(agent, cfg_path=Path().cwd()/'cfg'/'pg_ac.yaml', cfg_args=dict(save_video=True,testing=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2edb556b-187c-4662-a1df-60dc87917930",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video loop autoplay  >\n",
       " <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
       " Your browser does not support the video tag.\n",
       " </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not skip_training:\n",
    "    video = Video(Path().cwd()/'results'/'InvertedPendulum-v4'/'video'/'test'/'ex6-episode-0.mp4',\n",
    "    embed=True, html_attributes=\"loop autoplay\") # Set html_attributes=\"controls\" for video control\n",
    "    display(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "54640b32",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f83948189f99f90b4085c2d303b547ad",
     "grade": true,
     "grade_id": "cell-09564874b32375cf",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout\n",
    "\"TEST\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d432792",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "13b4216c279dd80ba4512330ce718bdd",
     "grade": false,
     "grade_id": "cell-5db97bc9fe1b8e96",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='Q1'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <h3><b>Student Question 1.1</b> Relationship between actor-critic and REINFORCE with baseline (10 points) </h3> \n",
    "\n",
    "What is the relationship between actor-critic and REINFORCE with baseline?\n",
    "            \n",
    "üîù\t<a href='#TOC'><b>Table of Contents</b></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7662c12-4b22-48ca-85cc-d389b77dde79",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9e350ecacc72df859b8ea1279bba8b20",
     "grade": false,
     "grade_id": "cell-af3dccf8c7e41349",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "<h5><b>Options</b></h5>\n",
    "\n",
    "1. Both actor-critic and REINFORCE use boostrapping to update their parameters. \n",
    "2. Both methods use Monte-Carlo estimates for updating their parameters.\n",
    "3. The baseline in REINFORCE is the state value function for actor-critic.\n",
    "4. Both methods require full-trajectories before they can update their parameters.\n",
    "5. Both methods can update their parameters during each timestep.\n",
    "6. Actor-critic uses bootstrapping to update its parameters while REINFORCE does not.\n",
    "\n",
    "Select the **two** most appropriate answers. Selecting more than 2 answers results in zero points from this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4875db20-b21d-4c28-b2ca-c7f2e46fffe2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sq1_1 = [3, 6] # Select the most approapriate answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4810fe-a2b7-44cd-93b1-a1b2d082c2ad",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3beea4b65c1e4d7a95ab8a1ae1600bb9",
     "grade": false,
     "grade_id": "cell-d838cdbf4808c6ff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "The cells below are used for autograding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1a6b3310-7e16-4408-9d74-6555c1fc7ed3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1de4c11b92c17597e4ac9050802b3eaa",
     "grade": true,
     "grade_id": "cell-0e00f76e0960536d",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert 1 <= len(sq1_1) <= 2\n",
    "assert set(sq1_1) < set(range(1, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950514e5-56e9-488d-a9b6-b231e7d5262e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1702e61d7c49da20be80181b5c9d064e",
     "grade": true,
     "grade_id": "cell-26b1c613a6f06ff9",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5dfa77-0d04-4384-84df-88f14550d8b4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e76afee0618f7073f2ebef8e947b465b",
     "grade": true,
     "grade_id": "cell-9aa5fe70a03ab88f",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b88b08e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a57b56668c6aed15c3d1dcaa0c5e0be7",
     "grade": false,
     "grade_id": "cell-05a96ed4b54d0a0c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "<a id='Q2'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <h3><b>Student Question 1.2</b> Advantage (5 points) </h3> \n",
    "\n",
    "How can the value of advantage be intuitively interpreted? (Your answer should not be longer than 10 sentences).\n",
    "    \n",
    "üîù\t<a href='#TOC'><b>Table of Contents</b></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3bac64",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c97f49161088ab47f866a42e9dd909a4",
     "grade": true,
     "grade_id": "cell-7ea462e5360ad185",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "The advantage value represents how much better or worse a specific action is compared to the average expected return from a given state under the current policy. \n",
    "\n",
    "A positive advantage indicates that the action outperforms the policy's baseline, encouraging the policy to favor it more in future updates. \n",
    "\n",
    "Whereas, a negative advantage suggests the action underperforms, prompting the policy to reduce its probability. \n",
    "\n",
    "This measure helps reduce variance in policy gradient estimates by subtracting a state-dependent baseline, leading to more stable learning. \n",
    "\n",
    "It essentially quantifies the relative benefit of an action, guiding the agent toward optimal decisions without relying solely on absolute rewards."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4db6c52",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c98268593ad7780ce49ad86a1e8f987c",
     "grade": false,
     "grade_id": "cell-9a3f2bca9650b8b5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='Q3'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <h3><b>Student Question 1.3</b> Bias and Variance Analysis (10 points) </h3> \n",
    "\n",
    "How does the implemented actor-critic method compare to REINFORCE in terms of bias and variance of the policy gradient estimation? Explain your answer. (Your answer should not be longer than 10 sentences).\n",
    "    \n",
    "üîù\t<a href='#TOC'><b>Table of Contents</b></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106d5916",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "22175d03d3f4b28b443696bddd162af1",
     "grade": true,
     "grade_id": "cell-74f7530fd7c8fef3",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "The actor-critic method  provides policy gradient estimates with lower variance but potentially higher bias compared to REINFORCE. \n",
    "\n",
    "REINFORCE relies on Monte Carlo sampling of full episode returns to compute gradients, resulting in unbiased estimates since it uses actual trajectory rewards without approximations. However, this leads to high variance due to the stochastic nature of entire episodes and environmental noise. \n",
    "\n",
    "Whereas, actor-critic uses a learned critic to estimate value functions and advantages via temporal difference (TD) learning, which bootstraps from current estimates. This bootstrapping reduces variance by smoothing out noisy returns with function approximation. Yet, it introduces some bias because the critic's value estimates are imperfect and depend on the accuracy of the learned model. \n",
    "\n",
    "The trade-off allows actor-critic to learn more efficiently in practice, especially in long-horizon tasks. Overall, the reduced variance often outweighs the introduced bias, leading to more stable training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ddf4e7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "600033db53328bf2d16d465b3aff68b2",
     "grade": false,
     "grade_id": "cell-57372114b7deef34",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='Q4'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <h3><b>Student Question 1.4</b> Controlling bias-variance tradeoff (10 points) </h3> \n",
    "\n",
    "How could the bias-variance tradeoff in actor-critic be controlled? (Your answer should not be longer than 10 sentences).\n",
    "    \n",
    "üîù\t<a href='#TOC'><b>Table of Contents</b></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03501249",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "719a83ac1efc28a51317240ab20e3168",
     "grade": true,
     "grade_id": "cell-bd37bcc37ef9fff6",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "To control bias-variance tradeoff in actor-critic: \n",
    "\n",
    "- **Generalized Advantage Estimation (GAE)**: Using hyperparameter $\\lambda$ to balance bias and variance. $\\lambda$ near 0 increases bias/lowers variance via TD updates. $\\lambda$ near 1 reduces bias/increases variance via Monte Carlo estimates.\n",
    "\n",
    "- **N-step Returns**: Adjusting bootstrapping horizon. Shorter n-steps increase bias but decrease variance. Longer n-steps reduce bias at the expense of increased variance.\n",
    "\n",
    "- **Critic Improvement**: Enhancing function approximation with deeper networks or ensembles to cut bias without raising variance much.\n",
    "\n",
    "- **Regularization Techniques**: Applying entropy bonuses or target networks to smooth updates and stabilize the tradeoff.\n",
    "\n",
    "- **Discount Factor ($\\gamma$)**: Tuning $\\gamma$ indirectly. Higher values extend horizon and may increase variance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc1e91e-5715-45b9-a2c2-4e8f0fd2fff2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2b1c367010d08ca7088a8580a920eb7d",
     "grade": false,
     "grade_id": "cell-5f74898cf5b2c817",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "\n",
    "# 3. Submitting <a id='3.'></a>\n",
    "Ensure all tasks and questions (in ```ex6_DDPG.ipynb``` and ```ex6_PG_AC.ipynb```) are answered and the necessary plots are saved in the appropriate locations. The relevant plots and files needed to be submitted for this assignment are:\n",
    "\n",
    "\n",
    "- Training performance plots:\n",
    "  - `pg_ac.png`: Training performance plots in terms of episode and episodic reward\n",
    "<br>\n",
    "\n",
    "  \n",
    "- Model files:\n",
    "  - `InvertedPendulum-v4_params.pt`: Trained model\n",
    "\n",
    "\n",
    "Ensure the model files and plots are saved in correct paths:\n",
    "- ```results/InvertedPendulum-v4/pg_ac.png``` Training result\n",
    "- ```results/InvertedPendulum-v4/model/InvertedPendulum-v4_params.pt``` Training Model\n",
    "\n",
    "\n",
    "<span style=\"color:red\"> **# IMPORTANT: DO NOT FORGET ANOTHER TASK IN ```ex6_DDPG.ipynb```** </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9269a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that skip training is set to True before submission\n",
    "assert skip_training == True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b0c6d7-563a-4037-9d4c-ef1422d7b657",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "89e8fd20b8a0b3230d25dc0d69962803",
     "grade": false,
     "grade_id": "cell-99c320f0e224a0c8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 3.1 Feedback <a id='3.1'></a>\n",
    "\n",
    "In order to help the staff of the course as well as the forthcoming students, it would be great if you could answer to the following questions in your submission:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2e7c42-211b-419b-a3c9-daeab45597f1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "016e22b96662eff6447f48f25857a230",
     "grade": false,
     "grade_id": "cell-09e6cdb34c71b984",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "1) How much time did you spend solving this exercise? (change the ```hrs``` variable below to a floating point number representing the number of hours taken e.g. 5.43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfa3e0a-f247-43f4-92cc-5b6e99c79049",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hrs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e49e4f-0803-4d11-9ac4-9f77bedfa52f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7c96fba064ac1fc2b00810fc1dc378a0",
     "grade": false,
     "grade_id": "cell-fa64dd33a8c904ef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "2) Difficulty of each task/question from 1-5 (int or float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fc5ed4-1957-4c5c-97fb-de2dc7c4362e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "T1 = None   # Implementing DDPG (20 points)\n",
    "Q1 = None   # Question 1.1 Relationship between actor-critic and REINFORCE with baseline (10 points)\n",
    "Q2 = None   # Question 1.2 Advantage (5 points)\n",
    "Q3 = None   # Question 1.3 Bias and Variance Analysis (10 points)\n",
    "Q4 = None   # Question 1.4 Controlling bias-variance tradeoff (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f6cdd1-ea58-4a06-a81b-1d7cc36f14a2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4dab816afcbe55502451543d8a576129",
     "grade": false,
     "grade_id": "cell-69fa22cf9bfa78b8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "3) How well did you understand the content of the task/question from 1-5? (int or float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27706e2f-2a35-4a6e-ad07-9af944b96dfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "T1 = None   # Implementing DDPG (20 points)\n",
    "Q1 = None   # Question 1.1 Relationship between actor-critic and REINFORCE with baseline (10 points)\n",
    "Q2 = None   # Question 1.2 Advantage (5 points)\n",
    "Q3 = None   # Question 1.3 Bias and Variance Analysis (10 points)\n",
    "Q4 = None   # Question 1.4 Controlling bias-variance tradeoff (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc810cc9-ba38-480d-a95e-178f875bc744",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e0204b1b962a537ae2e40333c7dfdbcb",
     "grade": false,
     "grade_id": "cell-2e02694ca4fcfa78",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "4) General feedback. Consider questions like:\n",
    "\n",
    "    - Did the content of the lecture relate well with the assignment?\n",
    "    - To what extent did you find the material to be potentially useful for your research and studies?\n",
    "    \n",
    "Please share any additional feedback, suggestions, or comments you have about the lecture, assignment, or course content. Your input is valuable in helping us improve the learning experience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6d30ad-8d44-4fe5-a642-121200f920d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "DOUBLE CLICK HERE TO EDIT, CLEAR THIS TEXT AND ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785254f3-48b6-44a6-ace6-0eae136d6396",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c456a1da33caaefda4a4a4c165be11d6",
     "grade": false,
     "grade_id": "cell-5086c1c7c783ad08",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# References <a id='4.'></a>\n",
    "Please use the following section to record references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be24169-8a32-4c87-9e15-3f6eee2364a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
