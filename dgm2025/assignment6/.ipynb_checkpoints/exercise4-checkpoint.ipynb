{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1479d98864ad484cb780a334fa67552e",
     "grade": false,
     "grade_id": "cell-3941e0c28ecf711b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exercise 4 - cGAN: Conditional GAN (4p)\n",
    "\n",
    "The goal of this exercise is get familiar with another type of GAN the cGAN and specifically a Least Squares Deep Convolutional one similar to Exercise 3. The original cGAN model was proposed by [Mirza, Osindero, 2014](https://arxiv.org/pdf/1411.1784).\n",
    "\n",
    "Conditional GANs are a form of supervised learning as opposed to the original GAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "skip_training = False  # Set this flag to True before validation and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98d57e95bab744702a07e57404aa169b",
     "grade": true,
     "grade_id": "cell-bd68b7386e29d846",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# During evaluation, this cell sets skip_training to True\n",
    "# skip_training = True\n",
    "\n",
    "import tools, warnings\n",
    "warnings.showwarning = tools.customwarn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms\n",
    "\n",
    "import tools\n",
    "import tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# When running on your own computer, you can specify the data directory by:\n",
    "# data_dir = tools.select_data_dir('/your/local/data/directory')\n",
    "data_dir = tools.select_data_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#device = torch.device('cuda:0')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd275621253cd028c5065035e3390f93",
     "grade": false,
     "grade_id": "cell-2212a6a282e966a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if skip_training:\n",
    "    # The models are always evaluated on CPU\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "04ce3d7c3c2e4c327a34405291398340",
     "grade": false,
     "grade_id": "cell-140f604a5cb368f8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Data\n",
    "\n",
    "We will use MNIST data in this exercise. **Note that we re-scale images so that the pixel intensities are in the range [-1, 1].**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a57252aa059b4324485613a29450837d",
     "grade": false,
     "grade_id": "cell-55039c5db5aa5d3a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Transform to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Scale images to [-1, 1]\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root=data_dir, train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.MNIST(root=data_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "batch_size = 100\n",
    "dataloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ceff023afd66794411ec51227791aa54",
     "grade": false,
     "grade_id": "cell-797591c879634741",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Generative adversarial networks\n",
    "\n",
    "Our task is to train a generative model of the data, that is a model from which we can draw samples that will have a distribution similar to the distribution of the training data (MNIST digits in our case)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f4f20e448314d57ee117320a604e56ab",
     "grade": false,
     "grade_id": "cell-9356f4dc68bfdc4e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Generator\n",
    "\n",
    "The generative model that we are going to train is:\n",
    "\\begin{align}\n",
    "z &\\sim N(0, I)\n",
    "\\\\\n",
    "x &= g(z)\n",
    "\\end{align}\n",
    "that is the data is generated by applying a nonlinear transformation to samples drawn from the standard normal distribution.\n",
    "\n",
    "We are going to model $g$ with a deep neural network created below. In DCGAN, the generator processes both noise and conditional information through separate paths before combining them.\n",
    "\n",
    "The proposed architecture for the generator:\n",
    "\n",
    "Noise path:\n",
    "\n",
    "* `ConvTranspose2d` layer with `kernel_size=4`, `stride=2`, `2*ngf` output channels, no bias,\n",
    "   followed by `BatchNorm2d` and `ReLU`.\n",
    "\n",
    "Conditional path:\n",
    "\n",
    "* Embedding layer for class labels with `embedding_dim=ngf`.\n",
    "* `ConvTranspose2d` layer with `kernel_size=4`, `stride=2`, `2*ngf` output channels, no bias,\n",
    "   followed by `BatchNorm2d` and `ReLU`.\n",
    "\n",
    "Combined path:\n",
    "\n",
    "* Concatenation of noise and conditional features\n",
    "* `ConvTranspose2d` layer with `kernel_size=4`, `stride=2`, `2*ngf` output channels, no bias,\n",
    "   followed by `BatchNorm2d` and `ReLU`.\n",
    "* `ConvTranspose2d` layer with `kernel_size=4`, `stride=2`, `ngf` output channels, no bias,\n",
    "   followed by `BatchNorm2d` and `ReLU`.\n",
    "* `ConvTranspose2d` layer with `kernel_size=4`, `stride=2`, `nc` output channels, no bias,\n",
    "   followed by `tanh`.\n",
    "\n",
    "The `tanh` nonlinearity guarantees that the output is between -1 and 1 which holds for our scaling of the training data.\n",
    "\n",
    "Notes:\n",
    "* **The exact architecture is not tested in this assignment.**\n",
    "* **The description above is not full. To get the correct output shape, you need to set correctly parameters `in_channels` and `padding` of the `ConvTranspose2d` layers and also `num_embeddings` of the `Embedding` layer. Note that training may fail for some padding schemes. If training fails but everything else looks correct, try changing the padding scheme.**\n",
    "* For concatenation you can use `torch.cat()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa027aba45a11249210a9a97eab0bf54",
     "grade": false,
     "grade_id": "Generator",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz=10, ngf=64, nc=1):\n",
    "        \"\"\"GAN generator.\n",
    "        \n",
    "        Args:\n",
    "          nz:  Number of elements in the latent code.\n",
    "          ngf: Base size (number of channels) of the generator layers.\n",
    "          nc:  Number of channels in the generated images.\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngf = ngf\n",
    "        self.nc = nc\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def forward(self, z, c, verbose=False):\n",
    "        \"\"\"Generate images by transforming the given noise tensor.\n",
    "        \n",
    "        Args:\n",
    "          z of shape (batch_size, nz, 1, 1): Tensor of noise samples. We use the last two singleton dimensions\n",
    "                          so that we can feed z to the generator without reshaping.\n",
    "          c of shape (batch_size, ): Conditioning. Tensor of labels as integers.\n",
    "          verbose (bool): Whether to print intermediate shapes (True) or not (False).\n",
    "        \n",
    "        Returns:\n",
    "          out of shape (batch_size, 1, 28, 28): Generated images.\n",
    "          \n",
    "        Hint: Remember to concatenate x and y\n",
    "        \"\"\"\n",
    "        batch_size, _, image_size_1, image_size_2 = z.shape\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b49d7459a8f04d2a9fb8dc0e46ffd8e7",
     "grade": true,
     "grade_id": "cell-b8094a3c35826d3c",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_Generator_shapes():\n",
    "    nz = 10\n",
    "    netG = Generator(nz, ngf=32, nc=1)\n",
    "\n",
    "    batch_size = 32\n",
    "    noise = torch.randn(batch_size, nz, 1, 1)\n",
    "    c = torch.randint(0, 10, (batch_size,)).type(torch.LongTensor)\n",
    "    out = netG(noise, c, verbose=True)\n",
    "\n",
    "    assert out.shape == torch.Size([batch_size, 1, 28, 28]), f\"Bad shape of out: out.shape={out.shape}\"\n",
    "    print('Success')\n",
    "\n",
    "test_Generator_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "59b4aa80fe4b3f86dc6169411aa57b6c",
     "grade": true,
     "grade_id": "Generator_shapes",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cell tests Generator shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ab5a58be5bcef66ea9316f080270a0e9",
     "grade": false,
     "grade_id": "cell-0151d274de94f50d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Loss for training the generator\n",
    "\n",
    "The generative model will be guided by a discriminator whose task is to separate (classify) data into two classes:\n",
    "* true data (samples from the training set)\n",
    "* generated data (samples generated by the generator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7bb6fa5353ab5f0262705a5fea9b38e2",
     "grade": false,
     "grade_id": "cell-3f77648eb2fe0ea1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Establish convention for real and fake labels during training\n",
    "real_label = 1.\n",
    "fake_label = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1c9b1dd7fbd9a62266611a5769a5d74f",
     "grade": false,
     "grade_id": "cell-7f59b33f30149a9e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The task of the generator is to confuse the discriminator as much as possible, which is the case when the distribution produced by the generator perfectly replicates the data distribution.\n",
    "\n",
    "In the cell below, you need to implement the loss function which is used to train the generator. The loss should be the `F.mse_loss` loss computed with `real_label` as targets for the generated samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3d8a34dae1657289da6abb8920657dc6",
     "grade": false,
     "grade_id": "Generator_loss",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generator_loss(netD, fake_images, fake_cond):\n",
    "    \"\"\"Loss computed to train the GAN generator.\n",
    "\n",
    "    Args:\n",
    "      netD: The discriminator whose forward function takes inputs of shape (batch_size, 1, 28, 28)\n",
    "         and produces outputs of shape (batch_size, 1).\n",
    "      fake_images of shape (batch_size, 1, 28, 28): Fake images produces by the generator.\n",
    "      fake_cond of shape (batch_size, ): Conditioning. Class labels as integers.\n",
    "\n",
    "    Returns:\n",
    "      loss: The mean of the mean squared error losses computed for all the samples in the batch.\n",
    "\n",
    "    Notes:\n",
    "    - Make sure that you process on the device given by `fake_images.device`.\n",
    "    - Use values of global variables `real_label`, `fake_label` to produce the right targets.\n",
    "    \"\"\"\n",
    "    batch_size, device = fake_images.size(0), fake_images.device\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a4dafaba203b864b362d98d7ee701607",
     "grade": false,
     "grade_id": "cell-0651b8d2a32dd1fa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_generator_loss(generator_loss):\n",
    "    class MyDiscriminator(nn.Module):\n",
    "        def forward(self, x, y):\n",
    "            out = torch.Tensor([0.2, 0.4, 0.9])\n",
    "            return out\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        batch_size = 3\n",
    "        netD = MyDiscriminator()\n",
    "        fake_images = torch.zeros(batch_size, 1, 28, 28)\n",
    "        fake_cond = torch.randint(0, 10, (batch_size,)).type(torch.LongTensor)\n",
    "        loss = generator_loss(netD, fake_images, fake_cond)\n",
    "        expected = torch.tensor(0.33666667342185974)\n",
    "        print('loss:', loss.item())\n",
    "        print('expected:', expected)\n",
    "        assert torch.allclose(loss, expected, rtol=1e-4, atol=1e-6), \"loss does not match expected value.\"\n",
    "    print('Success')\n",
    "test_generator_loss(generator_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "28c188a6c02b2f3a1dbe88ecc766b7da",
     "grade": true,
     "grade_id": "test_Generator_loss",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cell tests generator_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "79fa7070279973338ee8c0c144fc78d1",
     "grade": false,
     "grade_id": "cell-63faa114782d7e87",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Discriminator\n",
    "\n",
    "In DCGAN, the discriminator is a stack of only convolutional layers.\n",
    "\n",
    "The proposed architecture for the discriminator:\n",
    "\n",
    "Image path:\n",
    "\n",
    "* Conv2d layer with `kernel_size=4`,`stride=2`,`ndf` output channels, no bias, followed by `LeakyReLU(0.2)`.\n",
    "\n",
    "Conditional path:\n",
    "\n",
    "* Embedding layer for class labels with `embedding_dim=ndf`.\n",
    "* Conv2d layer with `kernel_size=4`,`stride=2`,`ndf` output channels, no bias, followed by `LeakyReLU(0.2)`.\n",
    "\n",
    "Combined path:\n",
    "\n",
    "* Concatenation of image and conditional features\n",
    "* `Conv2d` layer with `kernel_size=4`, `stride=2`, `4*ndf` output channels, no bias,\n",
    "   followed by `BatchNorm2d` and `LeakyReLU(0.2)`.\n",
    "* `Conv2d` layer with `kernel_size=4`, `stride=2`, `ndf` output channels, no bias,\n",
    "   followed by `BatchNorm2d` and `LeakyReLU(0.2)`.\n",
    "* `Conv2d` layer with `kernel_size=4`, `stride=2`, `1` output channel, no bias,\n",
    "   followed by `sigmoid`.\n",
    "\n",
    "Notes:\n",
    "* **The exact architecture is not tested in this assignment.**\n",
    "* **The description above is not full. To get the correct output shape, you need to set correctly parameters `in_channels` and `padding` of the `Conv2d` layers and also `num_embeddings` of the `Embedding` layer. Note that training may fail for some padding schemes. If training fails but everything else looks correct, try changing the padding scheme.**\n",
    "* For concatenation you can use `torch.cat()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "14bf73e6e5078a9a36dd42240dce48f0",
     "grade": false,
     "grade_id": "Discriminator",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, nc=1, ndf=64):\n",
    "        \"\"\"GAN discriminator.\n",
    "        \n",
    "        Args:\n",
    "          nc:  Number of channels in images. Here we work with black/white images so nc=1\n",
    "          ndf: Base size (number of channels) of the discriminator layers.\n",
    "        \"\"\"\n",
    "        \n",
    "        super(Discriminator, self).__init__()\n",
    "        self.nc = nc\n",
    "        self.ndf = ndf\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def forward(self, x, c, verbose=False):\n",
    "        \"\"\"Classify given images into real/fake.\n",
    "        \n",
    "        Args:\n",
    "          x of shape (batch_size, 1, 28, 28): Images to be classified.\n",
    "          c of shape (batch_size,): Conditioning numbers, class labels as integers\n",
    "          verbose (bool): Whether to print intermediate shapes (True) or not (False).\n",
    "        \n",
    "        Returns:\n",
    "          out of shape (batch_size,): Probabilities that images are real. All elements should be between 0 and 1.\n",
    "        \"\"\"\n",
    "        batch_size, _, image_size_1, image_size_2 = x.shape\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "659b2619a4452b95abf75fb0b43d3d01",
     "grade": false,
     "grade_id": "cell-cef1ff3c74404557",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_Discriminator_shapes():\n",
    "    batch_size = 32\n",
    "    netD = Discriminator(nc=1, ndf=32)\n",
    "    images = torch.ones(batch_size, 1, 28, 28)\n",
    "    \n",
    "    c = torch.randint(0, 10, (batch_size,)).type(torch.LongTensor)\n",
    "    out = netD(images, c, verbose=True)\n",
    "\n",
    "    assert out.shape == torch.Size([batch_size]), f\"Bad shape of out: out.shape={out.shape}\"\n",
    "    print('Success')\n",
    "\n",
    "test_Discriminator_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "87eed2117e3e09c06367539839606230",
     "grade": true,
     "grade_id": "Discriminator_shapes",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cell tests Discriminator shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "caee9ee8a815b685c4cd3564c834956a",
     "grade": false,
     "grade_id": "cell-51681d3003e07996",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Loss for training the discriminator\n",
    "\n",
    "The discriminator is trained to solve a binary classification problem: to separate real data from generated samples. Thus, the output of the discriminator should be a scalar between 0 and 1.\n",
    "\n",
    "You need to implement the loss function used to train the discriminator. The dicriminator uses the `F.mse_loss` loss using `real_label` as targets for real samples and `fake_label` as targets for generated samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8572f40c0b38804b489e802ebc2ed245",
     "grade": false,
     "grade_id": "discriminator_loss",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(netD, real_images, real_cond, fake_images, fake_cond):\n",
    "    \"\"\"Loss computed to train the GAN discriminator.\n",
    "\n",
    "    Args:\n",
    "      netD: The discriminator.\n",
    "      real_images of shape (batch_size, 1, 28, 28): Real images.\n",
    "      real_cond of shape (batch_size, ): Conditioning on the real images. Class labels as integers\n",
    "      fake_images of shape (batch_size, 1, 28, 28): Fake images produces by the generator.\n",
    "      fake_cond of shape (batch_size, ): Conditioning on the fake images. Class labels as integers\n",
    "      \n",
    "    Returns:\n",
    "      d_loss_real: The mean of the mean squared error losses computed on the real_images.\n",
    "      D_real: Mean output of the discriminator for real_images. This is useful for tracking convergence.\n",
    "      d_loss_fake: The mean of the mean squared error losses computed on the fake_images.\n",
    "      D_fake: Mean output of the discriminator for fake_images. This is useful for tracking convergence.\n",
    "\n",
    "    Notes:\n",
    "    - Make sure that you process on the device given by `real_images.device`.\n",
    "    - Use values of global variables `real_label`, `fake_label` to produce the right targets.\n",
    "    \"\"\"\n",
    "    batch_size, device = real_images.shape[0], real_images.device\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1136f8a9e2085236848608a550d70225",
     "grade": true,
     "grade_id": "cell-461f1d2ee56f035d",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_discriminator_loss_1():\n",
    "    netD = Discriminator(nc=1, ndf=64)\n",
    "    batch_size = 32\n",
    "    real_images = fake_images = torch.ones(batch_size, 1, 28, 28)\n",
    "    \n",
    "    real_labels = torch.full((batch_size,), real_label, device=device)\n",
    "    fake_labels = torch.full((batch_size,), fake_label, device=device)\n",
    "    \n",
    "    real_cond = torch.randint(0, 10, (batch_size,)).type(torch.LongTensor)\n",
    "    fake_cond = torch.randint(0, 10, (batch_size,)).type(torch.LongTensor)\n",
    "\n",
    "    d_loss_real, D_real, d_loss_fake, D_fake = discriminator_loss(\n",
    "                                                netD, real_images, real_cond, \n",
    "                                                fake_images, fake_cond)\n",
    "    assert d_loss_real.shape == torch.Size([]), \"d_loss_real should be a scalar tensor.\"\n",
    "    assert 0 < D_real < 1, \"D_real should be a scalar between 0 and 1.\"\n",
    "    assert d_loss_fake.shape == torch.Size([]), \"d_loss_fake should be a scalar tensor.\"\n",
    "    assert 0 < D_fake < 1, \"D_fake should be a scalar between 0 and 1.\"\n",
    "    print('Success')\n",
    "\n",
    "test_discriminator_loss_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f8e3d1c87413b14efa9dae941b1cf980",
     "grade": true,
     "grade_id": "cell-c7f885008c59d953",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_discriminator_loss_2(discriminator_loss):\n",
    "    with torch.no_grad():\n",
    "        class MyDiscriminator(nn.Module):\n",
    "            def forward(self, x, y):\n",
    "                if (x == 0).all():\n",
    "                    return torch.Tensor([0.2, 0.3, 0.5])\n",
    "                elif (x == 1).all():\n",
    "                    return torch.Tensor([0.3, 0.8, 0.5])\n",
    "        \n",
    "        batch_size = 3\n",
    "        \n",
    "        netD = MyDiscriminator()\n",
    "\n",
    "        fake_images = torch.zeros(batch_size, 1, 28, 28)\n",
    "        real_images = torch.ones(batch_size, 1, 28, 28)\n",
    "        real_labels = torch.ones((batch_size,))\n",
    "        fake_labels = torch.zeros((batch_size,))\n",
    "        real_cond = torch.randint(0, 10, (batch_size,)).type(torch.LongTensor)\n",
    "        fake_cond = torch.randint(0, 10, (batch_size,)).type(torch.LongTensor)\n",
    "        \n",
    "        d_loss_real, D_real, d_loss_fake, D_fake = discriminator_loss(netD, \n",
    "                                                                      real_images, real_cond,\n",
    "                                                                      fake_images, fake_cond)\n",
    "        expected = torch.tensor(0.25999999046325684)\n",
    "        print('d_loss_real:', d_loss_real.item())\n",
    "        print(f\"expected d_loss_real: {expected:.16f}\")\n",
    "        assert torch.allclose(d_loss_real, expected, rtol=1e-4, atol=1e-6), \"d_loss_real does not match expected value.\"\n",
    "        \n",
    "        expected = 0.5333333611488342\n",
    "        print('D_real:', D_real)\n",
    "        print(f\"expected D_real: {expected:.16f}\")\n",
    "        assert np.allclose(D_real, expected, rtol=1e-4, atol=1e-6), \"D_real does not match expected value.\"\n",
    "        \n",
    "        expected = torch.tensor(0.12666666507720947)\n",
    "        print('d_loss_fake:', d_loss_fake.item())\n",
    "        print(f\"expected d_loss_fake: {expected:.16f}\")\n",
    "        assert np.allclose(d_loss_fake, expected, rtol=1e-4, atol=1e-6), \"d_loss_fake does not match expected value.\"\n",
    "\n",
    "        expected = 0.3333333432674408\n",
    "        print('D_fake:', D_fake)\n",
    "        print(f\"expected D_fake: {expected:.16f}\")\n",
    "        assert np.allclose(D_fake, expected, rtol=1e-4, atol=1e-6), \"D_fake does not match expected value.\"\n",
    "        \n",
    "    print('Success')\n",
    "    \n",
    "test_discriminator_loss_2(discriminator_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "83b2899ca86ffec668ef600744fdb240",
     "grade": true,
     "grade_id": "Discriminator_loss",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cell tests discriminator_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d2ce91d7e84c593bcd3eb8568b086cea",
     "grade": false,
     "grade_id": "cell-32a46a6724373e1b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Evaluation of quality of generated samples\n",
    "\n",
    "We would like to evaluate the quality of the generated samples using some metric. Designing such a metric is not a trivial task. The most popular metric for assessing the quality of generated images is FrÃ©chet Inception Distance (FID) [(Heusel et al., 2017)](https://arxiv.org/abs/1706.08500). The FID score compares the distribution of intermediate activations when real or generated samples are passed through an Inception network. The Inception network is a specific type of a convolutional neural network that is pre-trained on image classification tasks.\n",
    "\n",
    "In this exercise, we do not generate natural images and therefore we do not use the Inception network to compute the activations. Instead, we use a simple convolutional neural network trained to classify MNIST digits. Therefore, we call the metric FD score (dropping the word *Inception*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f93c4e446fa89f08395d80db52bae206",
     "grade": false,
     "grade_id": "cell-7292f1f13a3359dd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import fd\n",
    "\n",
    "# Load an FD scorer pre-trained on MNIST\n",
    "fdscore = fd.FDScore.pretrained()\n",
    "fdscore.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fbe7284b80697efad494a5b4e711827f",
     "grade": false,
     "grade_id": "cell-1b6b5eca75e178fe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Score on uniform noise in the range [-1, 1]\n",
    "samples = torch.rand(10000, 1, 28, 28).to(device)\n",
    "samples = (samples - 0.5) * 2\n",
    "score = fdscore.calculate(samples)\n",
    "print(f'Score on Gaussian noise: {score:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9998ffb799885a60661494c991679147",
     "grade": false,
     "grade_id": "cell-bebdfbe98e8010dc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Score on real MNIST digits\n",
    "samples = torch.stack([testset[i][0] for i in range(10000)]).to(device)\n",
    "score = fdscore.calculate(samples)\n",
    "print(f'Score on MNIST: {score:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1ac85d9d8c5eba3ee99bb50564ae4f1d",
     "grade": false,
     "grade_id": "cell-619a00b55e2632b3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Training GANs\n",
    "\n",
    "We will now train a GAN. To assess the quality of the generated samples, we will use a simple scorer loaded in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5cf83e174431e74bf90221cdf5aef65f",
     "grade": false,
     "grade_id": "cell-f306dde125361541",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the network\n",
    "nz = 10\n",
    "netG = Generator(nz=nz, ngf=64, nc=1)\n",
    "netD = Discriminator(nc=1, ndf=64)\n",
    "\n",
    "netD = netD.to(device)\n",
    "netG = netG.to(device)\n",
    "\n",
    "# Custom weights initialization\n",
    "# This is very important for this model as the training can be very unstable without this\n",
    "def weights_init(net):\n",
    "    classname = net.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(net.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(net.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(net.bias.data, 0)\n",
    "        \n",
    "netD.apply(weights_init)\n",
    "netG.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f1763c82c0b0a7deee85710f259a583f",
     "grade": false,
     "grade_id": "cell-e5478e8a7afe65cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Training loop\n",
    "\n",
    "Implement the training loop in the cell below. The recommended hyperparameters:\n",
    "* Optimizer of the discriminator: Adam with learning rate 0.0002 and `betas=(0.5, 0.999)`\n",
    "* Optimizer of the generator:     Adam with learning rate 0.0002 and `betas=(0.5, 0.999)`\n",
    "\n",
    "Hints:\n",
    "- We will use the FD score to assess the quality of the generated samples. Your cGAN should have the FD score below 10. This level can be reached after 5 epochs. Note that the score is stochastic and it can fluctuate during training. At convergence, the FD score can fluctuate in the range [3, 9]. The training should take around 30 minutes when ran for 7 epochs on JupyterHub. If you have access to a GPU you are welcome to let your cGAN train for longer, and you should get better results.\n",
    "- You can use the following code to track the training progress. The code plots some generated images and computes the score that we use to evaluate the trained model. Note that the images fed to the scorer need to be normalized to be in the range [-1, 1].\n",
    "```python\n",
    "with torch.no_grad():\n",
    "    # Gennerate images\n",
    "    z = torch.randn(100, nz, 1, 1, device=device)\n",
    "    c = torch.randint(0, 10, (100,)).type(torch.LongTensor)\n",
    "    samples = netG(z, c)\n",
    "\n",
    "    # Plot generated images\n",
    "    tools.plot_generated_samples(samples[:144])\n",
    "\n",
    "    # Compute score\n",
    "    score = fdscore.calculate(samples)\n",
    "    scores.append(score.item())\n",
    "    print(f'FD score: {score:.5f}')\n",
    "```\n",
    "- You can track `D_real` and `D_fake` returned by function `discriminator_loss()`. When it is hard for the discriminator to separate real and fake images, their values are close to 0.5.\n",
    "- Remember to detach `fake_images`, which you generate with the `Generator`, before you pass it to the `Discriminator` via the function like so `discriminator_loss(..., fake_images.detach(), ...)`.\n",
    "- You can use the real labels of the batch `real_cond` as your `fake_cond`, which you pass to your `Generator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7f5bf5587613f3037280581522a2123",
     "grade": false,
     "grade_id": "training_loop",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not skip_training:\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    #optimizerD = ...\n",
    "    #optimizerG = ...\n",
    "    \n",
    "    num_epochs = 3\n",
    "    scores = []\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (real_images, real_cond) in enumerate(dataloader):\n",
    "            real_images = real_images.to(device)\n",
    "            real_cond = real_cond.to(device)\n",
    "            batch_size = real_images.size(0)\n",
    "            \n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "            \n",
    "            ###########################\n",
    "            # Update the D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "            ###########################\n",
    "            \n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "            \n",
    "            ###########################\n",
    "            # Update G network: maximize log(D(G(z)))\n",
    "            ###########################\n",
    "            \n",
    "            # Logging\n",
    "            if (i+1) % 200 == 0:\n",
    "                print('[%2d/%d][%3d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f'\n",
    "                      % (epoch+1, num_epochs, i+1, len(dataloader),\n",
    "                         d_loss.item(), g_loss.item(), D_real, D_fake))\n",
    "                   \n",
    "        with torch.no_grad():\n",
    "            # Gennerate images\n",
    "            z = torch.randn(1000, nz, 1, 1, device=device)\n",
    "            c = torch.randint(0, 10, (1000,)).type(torch.LongTensor)\n",
    "            samples = netG(z, c)\n",
    "            \n",
    "            # Plot generated images\n",
    "            tools.plot_generated_samples(samples[:144])\n",
    "            \n",
    "            # Compute score\n",
    "            score = fdscore.calculate(samples)\n",
    "            scores.append(score.item())\n",
    "            print(f'FD score: {score:.5f}')\n",
    "    \n",
    "    plt.plot(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the model to disk (the pth-files will be submitted automatically together with your notebook)\n",
    "# Set confirm=False if you do not want to be asked for confirmation before saving.\n",
    "if not skip_training:\n",
    "    tools.save_model(netG, '1_cgan_g.pth', confirm=True)\n",
    "    tools.save_model(netD, '1_cgan_d.pth', confirm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "179e9125bf172f47e6585ba5bcb0eca9",
     "grade": false,
     "grade_id": "cell-d7405a9598633d45",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if skip_training:\n",
    "    nz = 10\n",
    "    netG = Generator(nz=nz, ngf=64, nc=1)\n",
    "    netD = Discriminator(nc=1, ndf=64)\n",
    "\n",
    "    tools.load_model(netG, '1_cgan_g.pth', device)\n",
    "    tools.load_model(netD, '1_cgan_d.pth', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b9cc068345cba97ea8314eff0a356da1",
     "grade": false,
     "grade_id": "cell-b46c56d8c838b7b3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## cGAN evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d62a9b557db4e7857a59b2f48479df81",
     "grade": true,
     "grade_id": "cell-e95aa3b7f714e6f9",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save generated samples (the pth-files will be submitted automatically together with your notebook)\n",
    "if not skip_training:\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(144, nz, 1, 1, device=device)\n",
    "        c = torch.randint(0, 10, (144,)).type(torch.LongTensor)\n",
    "        samples = netG(z, c)\n",
    "        torch.save(samples, '1_cgan_samples.pth')\n",
    "else:\n",
    "    samples = torch.load('1_cgan_samples.pth', map_location=lambda storage, loc: storage)\n",
    "\n",
    "tools.plot_generated_samples(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9a4667169ecd00b971e44301a4778c81",
     "grade": true,
     "grade_id": "test_quality",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute the FD score.\n",
    "torch.manual_seed(0)\n",
    "with torch.no_grad():\n",
    "    z = torch.randn(1000, nz, 1, 1, device=device)\n",
    "    c = torch.randint(0, 10, (1000,)).type(torch.LongTensor)\n",
    "    samples = netG(z, c)\n",
    "    tools.plot_generated_samples(samples[:144])\n",
    "    score = fdscore.calculate(samples)\n",
    "\n",
    "print(f'FD score: {score:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4e16a507a2e291cf3ce15c304a00115b",
     "grade": true,
     "grade_id": "cell-5fd96acb6ab62ef9",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cell generates fake images and feeds them to a pretrained MNIST digit classifier and then computes the accuracy of the classifications.\n",
    "# Your generator should generate such good images that the classifier labels them correctly with an accuracy >= 95%\n",
    "torch.manual_seed(0)\n",
    "classifier = fd.Classifier.pretrained()\n",
    "classifier.to(device)\n",
    "classifier.eval()\n",
    "with torch.no_grad():\n",
    "    z = torch.randn(1000, nz, 1, 1, device=device)\n",
    "    c = torch.randint(0, 10, (1000,)).type(torch.LongTensor)\n",
    "    fake_images = netG(z, c)\n",
    "    tools.plot_generated_samples(fake_images[:144])\n",
    "    \n",
    "    outputs = classifier(fake_images)\n",
    "    predicted_labels = torch.argmax(outputs, dim=1)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    correct = (predicted_labels == c).sum().item()\n",
    "    accuracy = correct / 1000 * 100\n",
    "\n",
    "print(f\"Accuracy of the classifications: {accuracy:.1f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a695feceb594aaaa54b3a7e14dbd9a2b",
     "grade": true,
     "grade_id": "cell-b1f8c5a705ca1079",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert skip_training, \"Set skip_training = True before submitting the assignment.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea9b31e0dfd137aa56d4b39623cf4b6c",
     "grade": true,
     "grade_id": "cell-23fa22d31962c3b9",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cell is used for grading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a8735af328553f5844de6d32e05840e3",
     "grade": false,
     "grade_id": "cell-37c0f19da39c5c9e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Conclusion</b>\n",
    "</div>\n",
    "\n",
    "In this notebook, we learned how to train a conditional DCGAN model for generating images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
