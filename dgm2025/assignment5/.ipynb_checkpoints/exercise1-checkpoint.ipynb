{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db7e7c7-4f3d-456f-9900-0bc12ae1638f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "13878e5fa4add6c707ff4f2dc20fb796",
     "grade": false,
     "grade_id": "cell-fb4da664fd39a930",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "def set_seeds(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # For CUDA\n",
    "    torch.cuda.manual_seed_all(seed)  # If you are using multi-GPU.\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seeds(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c242aaee-541a-44bb-a28a-d6ce17710e40",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ccc9e1baaa63f55aa3409fc371f6cc8a",
     "grade": false,
     "grade_id": "cell-f0577125bb43a11b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# Exercise 1 - The AR(1) Model (3 p)\n",
    "\n",
    "Assume that we have a time series $\\{y_t\\}$ governed by the autoregressive process\n",
    "\n",
    "$y_{t+1} = \\phi y_t + \\varepsilon_{t+1}$, with $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2)$\n",
    "\n",
    "For simplicity, let us assume stationarity, i.e. $|\\phi| < 1$. Assume that $\\sigma$ and $y_1$ are known.\n",
    "\n",
    "Your task:\n",
    "\n",
    "a) Derive the conditional likelihood for $t = 1,\\dots,T-1$ assuming fixed $\\sigma$: $\\,$ $\\prod_{t=1}^{T-1} p(y_{t+1} | y_t, \\phi)$\n",
    "\n",
    "b) Use the conditional likelihood derived in a) to derive the negative log-likelihood (NLL) loss function for estimating the value of $\\phi$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ede2f76-9600-4bc9-b1d1-fcf514b69bac",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "58ee4aeefd39b83c8bbd04ba71968019",
     "grade": true,
     "grade_id": "cell-ded9db6458835e73",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5894f858-b7aa-4a7c-9b2a-871b400b1c67",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "810194f38797eff0d5339d9de9f9f9ef",
     "grade": false,
     "grade_id": "cell-19182c9839c28fed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Let us apply the derived loss function this in practice to estimate the value of $\\phi$. Let us start by defining the loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a51f55e-544a-49fd-a061-869203a42394",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "44533ed4e9abc563d951d89473ac8d45",
     "grade": false,
     "grade_id": "cell-e03352f939c3eb02",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ar1_loss(phi_est, y, sigma):\n",
    "    \"\"\"\n",
    "    Compute the MSE-based loss (equivalent to negative log-likelihood\n",
    "    for fixed sigma^2) for an AR(1) process\n",
    "    \n",
    "    Args:\n",
    "        phi_est (torch.Tensor): Current estimate of phi (scalar).\n",
    "        y (torch.Tensor): Time series data of shape [T].\n",
    "        sigma (float): The variance of noise\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: MSE loss for the AR(1) residuals.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db1f52f-9c5e-4cc7-a4ca-5c43bc789eaf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ed4aa2201b20626f048c95cc1de0171f",
     "grade": false,
     "grade_id": "cell-4c16770196a0dde1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "For comparison, let us note that there exists also a closed-form solution for the MLE estimate of $\\phi$: \n",
    "\n",
    "$\\hat{\\phi}_\\text{MLE} = \\frac{\\sum_{t=1}^{T-1}y_t y_{t+1}}{\\sum_{t=1}^{T-1}y_t^2}$\n",
    "\n",
    "Let us implement that as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38553a32-315f-40a0-af48-63ff969b95ec",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d3d0cf464f19247694c0e1c3abc36edf",
     "grade": false,
     "grade_id": "cell-64f96d6ab24b6db9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def phi_mle_closed_form(y):\n",
    "    \"\"\"\n",
    "    Compute the closed-form Maximum Likelihood Estimate (MLE) of phi\n",
    "    for an AR(1) process, based on observed time series data.\n",
    "\n",
    "    Args:\n",
    "        y (np.ndarray): Time series data of shape [T].\n",
    "\n",
    "    Returns:\n",
    "        float: Closed-form MLE estimate of phi.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6256b8b3-0f27-4b8d-b1ef-cbb11cad5822",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0b25f796763f4b942c9ccdf76ac70db6",
     "grade": false,
     "grade_id": "cell-289b9029023b8251",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Then, let us create the optimization loop that uses the derived loss function. We will first generate a synthetic stationary AR(1) time series to serve as our data. After that, we run the optimization to estimate the value of $\\phi$ and compare the learned solution to both the ground-truth value and the closed-form MLE estimate.\n",
    "\n",
    "Note: due to the randomness in the data generation and the finite sample size, small deviations between the estimated and true values are expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0618bb4-e3af-4d4e-a785-d726650e8b5a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bf54aa898d0ca6a2bec28711f13a914b",
     "grade": true,
     "grade_id": "cell-531b97fb648cc73a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "T = 10000             # number of time points\n",
    "phi_true = 0.7        # true AR(1) coefficient\n",
    "sigma = 0.5           # known noise std (sigma^2 is noise variance)\n",
    "\n",
    "# Allocate array for observations\n",
    "y_np = np.zeros(T)\n",
    "\n",
    "# Generate the series: y_{t+1} = phi_true * y_t + noise\n",
    "for t in range(T - 1):\n",
    "    y_np[t+1] = phi_true * y_np[t] + sigma * np.random.randn()\n",
    "\n",
    "# Convert to torch.Tensor\n",
    "y_torch = torch.tensor(y_np, dtype=torch.float32)\n",
    "\n",
    "# The optimization setup\n",
    "phi_est = torch.nn.Parameter(torch.randn((), dtype=torch.float32))\n",
    "optimizer = torch.optim.SGD([phi_est], lr=1e-3)\n",
    "\n",
    "# Run optimization\n",
    "num_epochs = 6000\n",
    "for epoch in range(num_epochs):\n",
    "    loss = ar1_loss(phi_est, y_torch, sigma)\n",
    "    \n",
    "    # Backprop + update\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "phi_mle = phi_mle_closed_form(y_np)\n",
    "\n",
    "print(f\"True phi:                {phi_true}\")\n",
    "print(f\"Estimated phi (SGD):     {phi_est.item():.4f}\")\n",
    "print(f\"Closed-form MLE for phi: {phi_mle:.4f}\")\n",
    "\n",
    "assert np.abs(phi_est.item() - phi_true) < 0.03, \"Learned estimate for phi incorrect\"\n",
    "assert np.abs(phi_mle - phi_true) < 0.03, \"MLE estimate for phi incorrect\"\n",
    "\n",
    "print(\"Tests pass - success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ea28bd-38d8-41f5-8a35-0cc14b93e21e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
