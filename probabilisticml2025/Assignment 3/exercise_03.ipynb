{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8ad31f2f3b619608f4fd3c2d9167ade0",
     "grade": false,
     "grade_id": "cell-81c5a400584e4a8f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## CS-E4825 - Probabilistic Machine Learning D (spring 2025)\n",
    "\n",
    "Pekka Marttinen, Negar Safinianaini, Mihriban Kocak, Bo Zheng, Batuhan Avci.\n",
    "\n",
    "## Exercise 3, due on Friday 31st January at 10:15.\n",
    "\n",
    "### Contents\n",
    "1. Problem 1: Poisson-Gamma\n",
    "2. Problem 2: Multivariate Gaussian\n",
    "3. Problem 3: Posterior of regression weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "38bb2e5ebde49e1760a076b099d6e5a6",
     "grade": false,
     "grade_id": "cell-573bbaa2ef327be0",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "## Problem 1: Poisson-Gamma\n",
    "\n",
    "Suppose you have $N$ i.i.d. observations $\\mathbf{x}= \\{x_i\\}_{i=1}^N$ from a $\\operatorname{Poisson}(\\lambda)$ distribution with a rate parameter $\\lambda$ that has a conjugate prior \n",
    "\n",
    "$$\\lambda \\sim \\operatorname{Gamma}(a,b)$$\n",
    "\n",
    "with the shape and rate hyperparameters $a$ and $b$. Derive the posterior distribution $\\lambda|\\bf{x}$.\n",
    "\n",
    "Write your solutions in LateX or attach a picture in the answer cell provided below. You can add a picture using the command ```!(imagename_in_the_folder.jpg)```. Latex in here works similarly as you would write it normally! You can use some of the definitions from the exercise description as a reference. The list of valid Latex commands in Jypyter notebook can be found here: http://www.onemathematicalcat.org/MathJaxDocumentation/TeXSyntax.htm\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "Using Bayes' Theorem\n",
    "\n",
    "\n",
    "$\n",
    "p(\\lambda|x) = \\frac{p(x|\\lambda)p(\\lambda)}{p(x)}\n",
    "$\n",
    "\n",
    "Likelihood function\n",
    "\n",
    "$\n",
    "p(x|\\lambda) = \\prod_{i=1}^{N}\\frac{e^{-\\lambda} \\lambda^x}{x!}\n",
    "$\n",
    "\n",
    "Prior distribution\n",
    "\n",
    "$\n",
    "p(\\lambda) = Gamma(a,b) = \\frac{b^a \\lambda^{a-1} e^{-b\\lambda}}{\\Gamma(a)}\n",
    "$\n",
    "\n",
    "Putting the values to find posterior distribution\n",
    "\n",
    "\n",
    "$\n",
    "p(\\lambda|x) \\propto p(x|\\lambda)p(\\lambda) \\\\\n",
    "p(\\lambda|x) \\propto (\\prod_{i=1}^{N}\\frac{e^{-\\lambda} \\lambda^x_i}{x_i!}) \\frac{b^a \\lambda^{a-1} e^{-b\\lambda}}{\\Gamma(a)} \\\\\n",
    "$\n",
    "\n",
    "Dropping the terms which do not depend on \\lambda\n",
    "\n",
    "$\n",
    "p(\\lambda|x) \\propto (\\prod_{i=1}^{N} e^{-\\lambda} \\lambda^{x_i})  \\lambda^{a-1} e^{-b\\lambda} \\\\\n",
    "=> p(\\lambda|x) \\propto e^{-N\\lambda} \\lambda^{\\sum_{i=1}^{N} x_i}) \\lambda^{a-1} e^{-b\\lambda} \\\\\n",
    "=> p(\\lambda|x) \\propto e^{-(N+b)\\lambda} \\lambda^{a + \\sum x_i -1}\\\\\n",
    "$\n",
    "\n",
    "Ans. \n",
    "$\\lambda|x$ is\n",
    "\n",
    "\n",
    "$\n",
    "\\lambda | x \\propto \\Gamma(a + \\sum x_i, N + b) \\\\\n",
    "=> \\lambda | x \\propto \\Gamma(a', b')\n",
    "$\n",
    "where\n",
    "$\n",
    "a'= a+\\sum x_i \\\\\n",
    "b'= N + b\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c2d1bd8470ba33c5aa2596654e3cefbc",
     "grade": false,
     "grade_id": "cell-7fdfccb96ae5c3d1",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": true
    },
    "tags": []
   },
   "source": [
    "## Problem 2: Multivariate Gaussian\n",
    "\n",
    "Suppose we have $N$ i.i.d. observations $\\mathbf{X} = \\{\\mathbf{x}_i\\}_{i=1}^N$ from a multivariate Gaussian distribution $$\\mathbf{x}_i \\mid \\boldsymbol{\\mu} \\sim \\mathcal{N}(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})$$ with unknown mean parameter $\\boldsymbol{\\mu}$  and a known covariance matrix $\\boldsymbol{\\Sigma}$. As prior information on the mean parameter we have $$ \\boldsymbol{\\mu} \\sim \\mathcal{N}(\\mathbf{m_0}, \\mathbf{S_0}). $$\n",
    "\n",
    "__(a)__ Derive the posterior distribution $p(\\boldsymbol{\\mu}|\\mathbf{X})$ of the mean parameter $\\boldsymbol{\\mu}$. Write your solution in LateX or attach a picture of the solution in the cell below.\n",
    "\n",
    "__(b)__ Compare the Bayesian estimate (posterior mean) to the maximum likelihood estimate by generating $N=10$ observations from the bivariate Gaussian \n",
    "        $$\\mathcal{N}\\left(\\begin{bmatrix}0 \\\\ 0\\end{bmatrix}, \\begin{bmatrix}1 & 0 \\\\ 0 & 1\\end{bmatrix}\\right).$$\n",
    "For this you can use the Python function [numpy.random.normal](https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.normal.html), making use of the fact that the elements of the bivariate random vectors are independent. In the Bayesian case, use the prior with $\\mathbf{m_0} = [0,0]^T$ and $\\mathbf{S_0} = [\\begin{smallmatrix}0.1 & 0 \\\\ 0 & 0.1\\end{smallmatrix}]$. Report both estimates. Is the Bayesian estimate closer to the true value $\\boldsymbol{\\mu} = [0,0]^T$? Use the code template given below (after the answer cell) to complete your answer.\n",
    "\n",
    "Write your solutions to __(a)__ and __(b)__ in LateX or attach a picture in the answer cell provided below. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE\n",
    "Using Bayes' Theorem, \n",
    "\n",
    "$\n",
    "p(\\mu|X) = \\frac{p(X|\\mu)p(\\mu)}{p(X)} \\\\\n",
    "=> p(\\mu|X) \\propto p(X|\\mu)p(\\mu) \\\\\n",
    "=> p(\\mu|X) \\propto \\prod_{i=1}^{N}p(x_i|\\mu)p(\\mu) \\\\\n",
    "=> p(\\mu|X) \\propto (\\prod_{i=1}^{N}exp[-\\frac{1}{2}(x_i - \\mu)^{T}\\Sigma^{-1}(x_i - \\mu)])exp[-\\frac{1}{2}(\\mu - m_o)^{T}S_{o}^{-1}(\\mu - m_o)] \\\\\n",
    "=> p(\\mu|X) \\propto (\\prod_{i=1}^{N}exp[-\\frac{1}{2}(x_i^{T}\\Sigma^{-1}x_i + \\mu^{T}\\Sigma^{-1}\\mu - x_i^{T}\\Sigma^{-1}\\mu - \\mu^{T}\\Sigma^{-1}x_i])exp[-\\frac{1}{2}(\\mu^{T} S_{o}^{-1}\\mu + m_o^{T} S_{o}^{-1} m_o - m_o^{T} S_{o}^{-1}\\mu - \\mu^{T} S_{o}^{-1}m_o)]\n",
    "$\n",
    "\n",
    "Dropping all the terms which do not depend on $\\mu$\n",
    "\n",
    "$\n",
    "=> p(\\mu|X) \\propto (\\prod_{i=1}^{N}exp[-\\frac{1}{2}(\\mu^{T} \\Sigma^{-1}\\mu - x_i^{T}\\Sigma^{-1}\\mu - \\mu^{T}\\Sigma^{-1}x_i])exp[-\\frac{1}{2}(\\mu^{T} S_{o}^{-1}\\mu - m_o^{T} S_{o}^{-1}\\mu - \\mu^{T} S_{o}^{-1}m_o)]\n",
    "$\n",
    "\n",
    "Since $x_i^{T}\\Sigma^{-1}\\mu$ and $\\mu^{T}\\Sigma^{-1}x_i$ are scalar and transpose of each other, they are equal. \n",
    "\n",
    "For the same reason, $m_o^{T} S_{o}^{-1}\\mu = \\mu^{T} S_{o}^{-1}m_o$ \n",
    "\n",
    "Therefore, \n",
    "\n",
    "$\n",
    "=> p(\\mu|X) \\propto (\\prod_{i=1}^{N}exp[-\\frac{1}{2}(\\mu^{T} \\Sigma^{-1}\\mu - 2*x_i^{T}\\Sigma^{-1}\\mu)])exp[-\\frac{1}{2}(\\mu^{T} S_{o}^{-1}\\mu - 2*m_o^{T} S_{o}^{-1}\\mu)] \\\\\n",
    "=> p(\\mu|X) \\propto exp[-\\frac{1}{2}(N*\\mu^{T} \\Sigma^{-1}\\mu - 2*(\\sum_{i=1}^{N}x_i^{T})\\Sigma^{-1}\\mu)+(\\mu^{T} S_{o}^{-1}\\mu - 2*m_o^{T} S_{o}^{-1}\\mu)] \\\\\n",
    "=> p(\\mu|X) \\propto exp[-\\frac{1}{2}(\\mu^{T}( N\\Sigma^{-1} + S_{o}^{-1})\\mu - 2((\\sum_{i=1}^{N}x_i^{T})\\Sigma^{-1} + m_o^{T} S_{o}^{-1})\\mu)]\n",
    "$\n",
    "\n",
    "\n",
    "\n",
    "$\\textbf{Using the formula}: \\mu^TA\\mu - 2b^T\\mu = (\\mu - A^{-1}b)^TA(\\mu - A^{-1}b) - b^TA^{-1}b$\n",
    "\n",
    "$\n",
    "\\\\\n",
    "=> p(\\mu|X) \\propto exp[-\\frac{1}{2}([\\mu - ( N\\Sigma^{-1} + S_{o}^{-1})^{-1}((\\sum_{i=1}^{N}x_i^{T})\\Sigma^{-1} + m_o^{T} S_{o}^{-1})^T]^T [N\\Sigma^{-1} + S_{o}^{-1}][( N\\Sigma^{-1} + S_{o}^{-1})^{-1}(\\sum_{i=1}^{N}x_i^{T})\\Sigma^{-1} + m_o^{T} S_{o}^{-1})^T]) + const.]$ (leaving the terms not related to distribution)\n",
    "\n",
    "Now comparing with $(\\mu - \\mu_N)^T\\Sigma_N^{-1}(\\mu - \\mu_N) + const.$\n",
    "\n",
    "$\n",
    "\\Sigma_N^{-1} = N\\Sigma^{-1} + S_{o}^{-1} \\\\\n",
    "=> \\Sigma_N = (N\\Sigma^{-1} + S_{o}^{-1})^{-1} \\\\\n",
    "\\mu_N = ( N\\Sigma^{-1} + S_{o}^{-1})^{-1}((\\sum_{i=1}^{N}x_i^{T})\\Sigma^{-1} + m_o^{T} S_{o}^{-1})^T \\\\\n",
    "=> \\mu_N = \\Sigma_N (\\Sigma^{-1}(\\sum_{i=1}^{N}x_i) + S_{o}^{-1} m_o )\n",
    "$\n",
    "\n",
    "(a) Answer is \n",
    "$ P(\\mu|x) = \\mathcal{N}(\\mu_N, \\Sigma_N)$\n",
    "where \n",
    "\n",
    "$\n",
    "=> \\Sigma_N = (N\\Sigma^{-1} + S_{o}^{-1})^{-1} \\\\\n",
    "=> \\mu_N = \\Sigma_N (\\Sigma^{-1}(\\sum_{i=1}^{N}x_i) + S_{o}^{-1} m_o ) \\\\\n",
    "=> \\mu_N = \\Sigma_N (\\Sigma^{-1}(N\\bar{x}) + S_{o}^{-1} m_o )\n",
    "$\n",
    "\n",
    "where \n",
    "$\\bar{x}$ is the sample mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af88913931d4649db8324917756a5b72",
     "grade": false,
     "grade_id": "cell-e6a09ef8bf1f72d3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.60844597 -0.10898254]\n",
      "[-0.30422298 -0.05449127]\n",
      "Distance of MLE to true mean: 0.6181291821948062\n",
      "Distance of Bayesian estimate to true mean: 0.3090645910974031\n"
     ]
    }
   ],
   "source": [
    "# template for 2(b)\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "\n",
    "S0 = np.array([[0.1, 0],[0, 0.1]])\n",
    "Sigma = np.array([[1, 0],[0, 1]])\n",
    "N = 10\n",
    "\n",
    "# Sample N bivariate normal vectors\n",
    "# compute MLE and also the posterior mean solution\n",
    "\n",
    "# x = ? #EXERCISE\n",
    "# mle = ? #EXERCISE\n",
    "# posterior_mean = ? #EXERCISE \n",
    "\n",
    "# YOUR CODE HERE\n",
    "true_mean = np.array([0, 0])\n",
    "x = np.column_stack((np.random.normal(true_mean[0], np.sqrt(Sigma[0, 0]), N),\n",
    "                        np.random.normal(true_mean[1], np.sqrt(Sigma[1, 1]), N)))\n",
    "m0 = np.array([0, 0])\n",
    "mle = np.mean(x, axis = 0)\n",
    "\n",
    "S_N = np.linalg.inv(np.linalg.inv(S0) + N * np.linalg.inv(Sigma))\n",
    "posterior_mean = S_N @ (np.linalg.inv(S0) @ m0 + N * np.linalg.inv(Sigma) @ mle)\n",
    "\n",
    "\n",
    "print(mle)\n",
    "print(posterior_mean)\n",
    "\n",
    "# Determine which estimate is closer to the true mean\n",
    "mle_distance = np.linalg.norm(mle - true_mean)\n",
    "bayesian_distance = np.linalg.norm(posterior_mean - true_mean)\n",
    "\n",
    "print(\"Distance of MLE to true mean:\", mle_distance)\n",
    "print(\"Distance of Bayesian estimate to true mean:\", bayesian_distance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hence, the bayesian estimate is closer to the true mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19765\n",
      "0.29385\n"
     ]
    }
   ],
   "source": [
    "print((10 * 0.3953)/20)\n",
    "print(10 * 0.5877/20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ddf1e85bf2fabec6a07c3676a5945499",
     "grade": false,
     "grade_id": "cell-6f265c79745ea700",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "# Problem 3: Posterior of regression weights\n",
    "\n",
    "Suppose $y_{i}=\\mathbf{w}^{T}\\mathbf{x}_{i}+\\epsilon_{i},$ for $i=1,\\ldots,n,$ where $\\epsilon_{i}\\sim \\mathcal{N}(0,\\beta^{-1})$. Assume a prior $$\\mathbf{w} \\sim \\mathcal{N} (\\mathbf{0},\\alpha^{-1}\\mathbf{I}).$$ Use 'completing the square' to show that the posterior of $\\mathbf{w}$ is given by $p(\\mathbf{w} \\mid \\mathbf{y}, \\mathbf{x}, \\alpha, \\beta)=\\mathcal{N}(\\mathbf{w} \\mid \\mathbf{m}, \\mathbf{S}),$ where \n",
    "\\begin{align*}\n",
    "    \\mathbf{S} &= \\left( \\alpha \\mathbf{I} + \\beta \\sum_{i=1}^n \\mathbf{x}_i \\mathbf{x}_i^T \\right)^{-1}\\;, \\\\\n",
    "    \\mathbf{m} &= \\beta \\mathbf{S} \\sum_{i=1}^{n} y_i \\mathbf{x}_i.\n",
    "\\end{align*}\n",
    "\n",
    "Write your solution in LateX or attach a picture of the solution in the cell below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Bayes' Theorem, \n",
    "\n",
    "$\n",
    "p(w|y,x,\\alpha, \\beta) = \\frac{p(y,x,\\beta|w)p(w|\\alpha)}{p(y,x,\\alpha, \\beta)} \\\\\n",
    "=> p(w|y,x,\\alpha, \\beta) \\propto p(y,x,\\beta|w)p(w|\\alpha)\n",
    "$\n",
    "\n",
    "Prior distribution - \n",
    "\n",
    "$\n",
    "p(w|0, \\alpha^{-1}) = \\frac{\\sqrt{\\alpha}exp(\\frac{-1}{2}(w^2\\alpha))}{2\\pi} \\propto exp(\\frac{-1}{2}(w^2\\alpha))\n",
    "$\n",
    "\n",
    "Likelihood \n",
    "\n",
    "$\n",
    "p(y|x,w, \\beta^{-1}) = \\prod_{i=1}^{N}\\frac{\\sqrt{\\beta}exp(\\frac{-1}{2}(y_i - w^Tx_i)^2\\beta))}{2\\pi} \\propto \\prod_{i=1}^{N}exp(\\frac{-1}{2}(y_i - w^Tx_i)^2\\beta))\n",
    "$\n",
    "\n",
    "Therefore, posterior distribution \n",
    "\n",
    "$\n",
    "p(w|y,x,\\alpha, \\beta) \\propto exp(\\frac{-1}{2}(w^2\\alpha))(\\prod_{i=1}^{N}exp(\\frac{-1}{2}(y_i - w^Tx_i)^2\\beta))) \\\\\n",
    "=> p(w|y,x,\\alpha, \\beta) \\propto exp[\\frac{-1}{2}(w^2\\alpha)]exp[\\frac{-1}{2} (\\sum_{i=1}^{N}(y_i - w^Tx_i))^2\\beta)] \\\\\n",
    "=> p(w|y,x,\\alpha, \\beta) \\propto exp[\\frac{-1}{2}(w^2\\alpha + (\\sum_{i=1}^{N}(y_i - w^Tx_i))^2\\beta)] \\\\\n",
    "=> p(w|y,x,\\alpha, \\beta) \\propto exp[\\frac{-1}{2}(w^2\\alpha + [(\\sum_{i=1}^{N}y_i)^2 + (\\sum_{i=1}^{N}w^Tx_i)^2 - 2(\\sum_{i=1}^{N}y_iw^Tx_i)]\\beta)] \\\\\n",
    "=> p(w|y,x,\\alpha, \\beta) \\propto exp[\\frac{-1}{2}(w^Tw\\alpha + [(\\sum_{i=1}^{N}y_i)^2 + (w^T\\sum_{i=1}^{N}x_i x_i^T w) - 2(\\sum_{i=1}^{N}y_iw^Tx_i)]\\beta)] \\\\\n",
    "=> p(w|y,x,\\alpha, \\beta) \\propto exp[\\frac{-1}{2}(w^T(\\alpha + \\beta \\sum_{i=1}^{N}x_i x_i^T )w + \\beta (\\sum_{i=1}^{N}y_i)^2  - 2\\beta(\\sum_{i=1}^{N}y_iw^Tx_i)]\n",
    "$\n",
    "\n",
    "Dropping the terms which do not depend on w\n",
    "\n",
    "$\n",
    "=> p(w|y,x,\\alpha, \\beta) \\propto exp[\\frac{-1}{2}(w^T(\\alpha + \\beta \\sum_{i=1}^{N}x_i x_i^T )w  - 2\\beta(\\sum_{i=1}^{N}y_iw^Tx_i)]\n",
    "$\n",
    "\n",
    "$\\textbf{Using the formula}: \\mu^TA\\mu - 2b^T\\mu = (\\mu - A^{-1}b)^TA(\\mu - A^{-1}b) - b^TA^{-1}b$\n",
    "\n",
    "We get - \n",
    "$\n",
    "A = (\\alpha + \\beta \\sum_{i=1}^{N}x_i x_i^T ) \\\\\n",
    "b = \\beta \\sum_{i=1}^{N}y_ix_i\n",
    "$\n",
    "\n",
    "Now we get posterior distribution as (leaving the terms not related to distribution)\n",
    "\n",
    "$\n",
    "=> p(w|y,x,\\alpha, \\beta) \\propto (\\mu - (\\alpha + \\beta \\sum_{i=1}^{N}x_i x_i^T )^{-1}\\beta \\sum_{i=1}^{N}y_ix_i)^T(\\alpha + \\beta \\sum_{i=1}^{N}x_i x_i^T )((\\mu - (\\alpha + \\beta \\sum_{i=1}^{N}x_i x_i^T )^{-1}\\beta \\sum_{i=1}^{N}y_ix_i))\n",
    " + const. $\n",
    "\n",
    "From this, we get \n",
    "\n",
    "$p(\\mathbf{w} \\mid \\mathbf{y}, \\mathbf{x}, \\alpha, \\beta)=\\mathcal{N}(\\mathbf{w} \\mid \\mathbf{m}, \\mathbf{S})$ \n",
    "\n",
    "where \n",
    "$\n",
    "S^{-1} = \\alpha I + \\beta \\sum_{i=1}^{N}x_i x_i^T \\\\\n",
    "=> S = (\\alpha I + \\beta \\sum_{i=1}^{N}x_i x_i^T)^{-1} \\\\\n",
    "m = (\\alpha I + \\beta \\sum_{i=1}^{N}x_i x_i^T )^{-1}\\beta(\\sum_{i=1}^{N}y_i x_i) \\\\\n",
    "m = \\beta S (\\sum_{i=1}^{N}y_i x_i)\n",
    "$\n",
    "\n",
    "Hence proved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
