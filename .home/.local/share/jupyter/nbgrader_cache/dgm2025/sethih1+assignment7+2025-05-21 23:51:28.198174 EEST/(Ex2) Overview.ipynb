{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dda26cf5-1b73-46aa-9935-9f4979e41060",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7eb7345a130368390eadb2598238a8e9",
     "grade": false,
     "grade_id": "cell-36362aea0f3495d9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Assignment 7: Exercise 2 \n",
    "\n",
    "**Deadline:** 22 May 2025 at 00:00\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f38ae9d-da27-426a-83de-55c184d0a1e6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "63a47d00a39a7d3d2fc5c0690443be11",
     "grade": false,
     "grade_id": "cell-69e3463eff830d59",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    },
    "tags": []
   },
   "source": [
    "## Tacotron Model: Architectural Overview (3 points)\n",
    "\n",
    "You’ve now built each component of the Tacotron text-to-speech pipeline and integrated HiFi-GAN for waveform synthesis.\n",
    "\n",
    "### Your task\n",
    "\n",
    "In this exercise, simply outline the role of each module and describe the shape of its inputs and outputs—showing how the model goes from raw text to a playable audio file in its **inference pipeline** (not training). \n",
    "\n",
    "No need to go in too much detail, just show us that you can provide a general description of each step in the architecture. In particular what the component does, its input and output. As you have already implemented the functions you can just reference the components (encoder, decoder) without mentioning the individual convolutional layers, etc ... .\n",
    "\n",
    "Feel free to include a graph in this exercise to accompany your explanation. \n",
    "\n",
    "Hints:\n",
    "- You can refer to the paper for the original tacotron architecture: [Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions](https://arxiv.org/abs/1712.05884)  \n",
    "- You should describe at least 5 components in the architecture (including the embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8078b839-abb8-4001-966b-14e7d08e9f9c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "29f73768bd11dced88b9f3e7e58e3db4",
     "grade": false,
     "grade_id": "cell-fa6c37b6462bcbdf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### *_Starting example_*\n",
    "\n",
    "#### 1. Character embeddings\n",
    "\n",
    "Convert a string raw characters into learned continuous vectors (embeddings) via a lookup table.\n",
    "\n",
    "- **Input:** A sequence of character IDs of length N.\n",
    "- **Output:** Embedding Tensor of shape (N, E).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a214f8-4380-451c-a3a9-a8010181e3e1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "44d243da238fb83a45c36f87716bd3b7",
     "grade": false,
     "grade_id": "cell-120158480e3bb2a7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Your answer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa55509d-bd7a-4aff-b207-be29a995b9ed",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "557eb589ba51cac91d5c37884fe09618",
     "grade": true,
     "grade_id": "cell-780393fe1b872907",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34832ee-5d0a-4172-8982-46ccd979dffd",
   "metadata": {
    "tags": []
   },
   "source": [
    "1. **Character Embeddings**  \n",
    "   Convert discrete symbol IDs into continuous vectors(embeddings) via a lookup table.  \n",
    "   - **Input:** Sequence of character IDs, length N  \n",
    "   - **Output:** Embedding tensor - (N, E)\n",
    "\n",
    "2. **Encoder**  \n",
    "   “Reads” the entire embedded text to produce a contextual memory.  \n",
    "   - **Input:** (N, E)  \n",
    "   - **Output:** Memory tensor → (N, D_enc)\n",
    "\n",
    "3. **Decoder Prenet**  \n",
    "\n",
    "   Pre-processes the previous mel-frame before feeding it to the attention and decoder.  \n",
    "   - **Input:** Last mel frame → (1, M)  \n",
    "   - **Output:** Prenet projection → (1, D_prenet)\n",
    "\n",
    "3. **Decoder Attention**  \n",
    "   At each step, uses the prenet output as a query to “focus” on the encoder memory.  \n",
    "   - **Input:**  \n",
    "     - Query: (1, D_prenet) \n",
    "     - Memory: (N, D_enc) \n",
    "     - mask \n",
    "   - **Output:** \n",
    "       - Context vector → (1, D_enc)\n",
    "       - Attention weights (D_enc, D_enc)\n",
    "\n",
    "5. **Decoder LSTM**  \n",
    "   Autoregressively generates one mel-spectrogram frame at a time.  \n",
    "   - **Input:** Concatenation of prenet output and attention context → (1, D_prenet + D_enc)\n",
    "   - **Output:**  \n",
    "     - Raw mel frame → (1, M)\n",
    "     - Updated decoder state (hidden/cell) for next step (gate output)\n",
    "\n",
    "6. **Postnet**  \n",
    "   Applies a small conv-net over the full mel sequence to sharpen details.  \n",
    "   - **Input:** Sequence of raw mel frames → (T, M)  \n",
    "   - **Output:** Refined mel-spectrogram → (T, M)\n",
    "\n",
    "7. **HiFi-GAN Vocoder**  \n",
    "   Upsamples the mel-spectrogram into a time-domain waveform.  \n",
    "   - **Input:** (T, M)  \n",
    "   - **Output:** Audio waveform → (L,) (where L ≫ T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dadfbb2-5f62-4e48-a17a-e67f30f66227",
   "metadata": {},
   "source": [
    "![](Images_solution/p1.1.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf488bf7-ac3f-4779-a0fa-f551dbdafe17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
