{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "837f58216003eb597202d8d7b1fbd6b1",
     "grade": false,
     "grade_id": "cell-7a3f456c34b89eee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cell is used for creating a button that hides/unhides code cells to quickly look only the results.\n",
    "# Works only with Jupyter Notebooks.\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true;\n",
    "function code_toggle() {\n",
    "if (code_show){\n",
    "$('div.input').hide();\n",
    "} else {\n",
    "$('div.input').show();\n",
    "}\n",
    "code_show = !code_show\n",
    "}\n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "132eeb5b19ec443344fc2d1ba5b3a920",
     "grade": false,
     "grade_id": "cell-f7ae18b6d83c0140",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Description:\n",
    "#   Exercise4 notebook.\n",
    "#\n",
    "# Copyright (C) 2018 Santiago Cortes, Juha Ylioinas\n",
    "#\n",
    "# This software is distributed under the GNU General Public \n",
    "# Licence (version 2 or later); please refer to the file \n",
    "# Licence.txt, included with the software, for details.\n",
    "\n",
    "# Preparations\n",
    "import os\n",
    "from PIL import Image\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from itertools import compress\n",
    "\n",
    "from scipy.ndimage import maximum_filter\n",
    "from scipy.ndimage import map_coordinates\n",
    "from scipy.ndimage import convolve1d as conv1\n",
    "from scipy.ndimage import convolve as conv2\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import ProjectiveTransform, SimilarityTransform, AffineTransform\n",
    "from skimage.measure import ransac\n",
    "\n",
    "from utils import gaussian2, maxinterp, circle_points\n",
    "\n",
    "import time\n",
    "\n",
    "# Select data directory\n",
    "if os.path.isdir('/coursedata'):\n",
    "    # JupyterHub\n",
    "    course_data_dir = '/coursedata'\n",
    "elif os.path.isdir('../../../coursedata'):\n",
    "    # Local installation\n",
    "    course_data_dir = '../../../coursedata'\n",
    "else:\n",
    "    # Docker\n",
    "    course_data_dir = '/home/jovyan/work/coursedata/'\n",
    "\n",
    "print('The data directory is %s' % course_data_dir)\n",
    "data_dir = os.path.join(course_data_dir, 'exercise-04-data/')\n",
    "print('Data stored in %s' % data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8dd98aab18fc1e6a8942d4f633d4cb01",
     "grade": false,
     "grade_id": "cell-0a1e464cf92a4ee3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# CS-E4850 Computer Vision Exercise Round 4\n",
    "\n",
    "The exercises should be solved and the solutions submitted via Aalto JupyterHub by the deadline. \n",
    "\n",
    "**Deliverables:**\n",
    "- **Jupyter notebook** (.ipynb) containing your solutions to the programming tasks. Do not change the name of the notebook file. It may result in 0 points for the exercise.\n",
    "\n",
    "**Important:**\n",
    "- Fill only the cells marked with `# YOUR CODE HERE`. Do not change function signatures.\n",
    "- You may add extra cells for your own tests, but **do not** overwrite global variables or edit locked cells.\n",
    "- **Never create new cells by menu commands \"Edit/Copy Cells\" and \"Edit/Paste Cells ...\"**. These commands create cells with duplicate ids and make autograding impossible. Use menu commands \"Insert/Insert Cell ...\" or the button with a plus sign to insert new cells.\n",
    "- **All notebooks contain hidden tests** which are used for grading. They are hidden inside read-only cells. Therefore, **the read-only cells should never be removed.** \n",
    "- **Note:** Visible tests mainly check the shapes and data types of your function’s output. Hidden tests check the correctness of your solution more thoroughly. Passing the visible tests does not guarantee full points for the exercise.\n",
    "- **Google Colab warning:** Uploading your assignment notebooks to Colab may cause problems. Colab can overwrite notebook metadata and break the autograding. To avoid this, we recommend copy-pasting your code into the notebooks fetched on JupyterHub. Sorry for the inconvenience.\n",
    "- Be sure that everything that you need to implement should work with the pictures specified by the assignments of this exercise round.\n",
    "- Running the cells in mixed order (which quite often happens while trying different things and debugging) may cause errors. While working on a particular cell be sure that you have freshly run all its preceding cells belonging to the same exercise.\n",
    "- **Before submitting**, simply run all the cells of the notebook (for example, select \"Restart & Run All\" in the menu) and check that all the cells run properly.\n",
    "- **Remember to submit your assignment!**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Fill your name and student number below.\n",
    "\n",
    "### Name:\n",
    "### Student number:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f79d8e248690e54c87d89971e9cfb88f",
     "grade": false,
     "grade_id": "cell-a6b7b421d8e44b8f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Exercise 1 - Matching Harris corner points (10 exercise points)\n",
    "\n",
    "In this exercise, you will get familiar with **Harris interest point detection** and **image patch matching** between two views of the same scene.\n",
    "\n",
    "First, Harris corners from two images of the same scene are detected. Then, image patches of size 15x15 pixels around each detected corner point is extracted. Finally, the patches are matched using similarity measures:\n",
    "- **SSD** (sum of squared differences) - *reference implementation*\n",
    "- **NCC** (normalized cross-correlation) - *your task*\n",
    "\n",
    "### Steps:\n",
    "- **1.1.** Harris corners using OpenCV\n",
    "- **1.2.** Harris corner extraction in a less black-box manner\n",
    "- **1.3.** Matching according to SSD measure\n",
    "- **1.4.** Matching using normalized cross-correlation (NCC)\n",
    "- **1.5.** Number of correct correspondences with NCC\n",
    "- **1.6.** Answer the question\n",
    "\n",
    "Familiarize yourself with the provided code in **1.1.-1.3.**, complete the tasks in **1.4.** and **1.5.**, and answer the question in **1.6.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3c3dac0e5f5248ec68a93cfb384083e9",
     "grade": false,
     "grade_id": "cell-2301ae7f42ec6a97",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 1.1. Harris corners using OpenCV ###\n",
    "\n",
    "This example part illustrates OpenCV computer vision library built-in capabilities to extract Harris corner points (source: https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_feature2d/py_features_harris/py_features_harris.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7a560be586eac61be01fb2576a0fa9af",
     "grade": false,
     "grade_id": "cell-f2b0fbb7a5b7e6c0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "I1 = imread(data_dir+'Boston1.png');\n",
    "R1 = cv2.cornerHarris(I1,2,3,0.04)\n",
    "\n",
    "# Take only the local maxima of the corner response function\n",
    "fp = np.ones((3,3))\n",
    "fp[1,1] = 0\n",
    "maxNR1 = maximum_filter(R1, footprint=fp, mode='constant')\n",
    "\n",
    "# Test if cornerness is larger than neighborhood\n",
    "cornerI1 = R1>maxNR1\n",
    "\n",
    "# Threshold for low value maxima\n",
    "maxCV1 = np.amax(R1)\n",
    "\n",
    "# Find centroids\n",
    "ret, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8((R1>0.0001*maxCV1)*cornerI1))\n",
    "\n",
    "# Define the criteria to stop and refine the corners\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.001)\n",
    "corners = cv2.cornerSubPix(I1,np.float32(centroids),(5,5),(-1,-1), criteria)\n",
    "kp1=corners.T\n",
    "\n",
    "# Display Harris keypoints\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(I1, cmap='gray')\n",
    "plt.plot([kp1[0]],[kp1[1]],'rx')\n",
    "plt.suptitle(\"Harris Corners using OpenCV\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "73bdebd6301a5afe9d619c0110ede557",
     "grade": false,
     "grade_id": "cell-f0534b9b9651d756",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 1.2. Harris corner extraction in a less black-box manner ###\n",
    "\n",
    "Familiarize yourself with the `harris` function for Harris corner detection, as it will be used in later parts of the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f79b1e38194a1799540e572582e6ea5e",
     "grade": false,
     "grade_id": "cell-aeee94e6265effb9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def harris(im, sigma=1.0, relTh=0.0001, k=0.04):\n",
    "    im = im.astype(float) # Make sure im is float\n",
    "    \n",
    "    # Get smoothing and derivative filters\n",
    "    g, _, _, _, _, _, = gaussian2(sigma)\n",
    "    _, gx, gy, _, _, _, = gaussian2(np.sqrt(0.5))\n",
    "    \n",
    "    # Partial derivatives\n",
    "    Ix = conv2(im, -gx, mode='constant')\n",
    "    Iy = conv2(im, -gy, mode='constant')\n",
    "    \n",
    "    # Components of the second moment matrix\n",
    "    Ix2Sm = conv2(Ix**2, g, mode='constant')\n",
    "    Iy2Sm = conv2(Iy**2, g, mode='constant')\n",
    "    IxIySm = conv2(Ix*Iy, g, mode='constant')\n",
    "    \n",
    "    # Determinant and trace for calculating the corner response\n",
    "    detC = (Ix2Sm*Iy2Sm)-(IxIySm**2)\n",
    "    traceC = Ix2Sm+Iy2Sm\n",
    "    \n",
    "    # Corner response function R\n",
    "    # \"Corner\": R > 0\n",
    "    # \"Edge\": R < 0\n",
    "    # \"Flat\": |R| = small\n",
    "    R = detC-k*traceC**2\n",
    "    maxCornerValue = np.amax(R)\n",
    "    \n",
    "    # Take only the local maxima of the corner response function\n",
    "    fp = np.ones((3,3))\n",
    "    fp[1,1] = 0\n",
    "    maxImg = maximum_filter(R, footprint=fp, mode='constant')\n",
    "    \n",
    "    # Test if cornerness is larger than neighborhood\n",
    "    cornerImg = R>maxImg\n",
    "    \n",
    "    # Threshold for low value maxima\n",
    "    y, x = np.nonzero((R>relTh*maxCornerValue)*cornerImg) \n",
    "    \n",
    "    # Convert to float\n",
    "    x = x.astype(float)\n",
    "    y = y.astype(float)\n",
    "    \n",
    "    # Remove responses from image borders to reduce false corner detections\n",
    "    r, c = R.shape\n",
    "    idx = np.nonzero((x<2)+(x>c-3)+(y<2)+(y>r-3))[0]\n",
    "    x = np.delete(x,idx)\n",
    "    y = np.delete(y,idx)\n",
    "    \n",
    "    # Parabolic interpolation\n",
    "    for i in range(len(x)):\n",
    "        _,dx=maxinterp((R[int(y[i]), int(x[i])-1], R[int(y[i]), int(x[i])], R[int(y[i]), int(x[i])+1]))\n",
    "        _,dy=maxinterp((R[int(y[i])-1, int(x[i])], R[int(y[i]), int(x[i])], R[int(y[i])+1, int(x[i])]))\n",
    "        x[i]=x[i]+dx\n",
    "        y[i]=y[i]+dy\n",
    "        \n",
    "    return x, y, cornerImg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d74911c0711649520c2cb3c7f00a6fea",
     "grade": false,
     "grade_id": "cell-36f9538031b81d3e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 1.3. Matching according to SSD measure ###\n",
    "\n",
    "Explore the provided example code to understand the following steps:\n",
    "- Detection of Harris corners in both images\n",
    "- Extraction of 15×15 image patches around each detected corner\n",
    "- **Computation of the sum of squared differences (SSD) between all pairs of patches**\n",
    "- Visualisation of the 40 best matches based on the SSD scores\n",
    "- Calculation of the number of correct matches\n",
    "\n",
    "Pay special attention to the **computation of the SSD measure**, as you will reuse and modify this part of the code later in the exercise.\n",
    "\n",
    "**The SSD measure** for two image patches, $f$ and $g$, is defined as\n",
    "<center>$SSD(f,g) = \\sum_{k,l}(g(k,l)-f(k,l))^{2}$</center> \n",
    "\n",
    "so that **the smaller** the SSD value **the more similar** the patches are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c9a315a3374cf8f4da474c8f045f6da6",
     "grade": false,
     "grade_id": "cell-85b512a29d5b2109",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LOCKED: Do not modify this cell. (Reference SSD pipeline)\n",
    "\n",
    "# Load images\n",
    "I1 = imread(data_dir+'Boston1.png')/255.\n",
    "I2 = imread(data_dir+'Boston2m.png')/255.\n",
    "\n",
    "# Harris corner extraction, take a look at the source code above\n",
    "x1, y1, cimg1 = harris(I1)\n",
    "x2, y2, cimg2 = harris(I2)\n",
    "\n",
    "# Pre-allocate the memory for the 15*15 image patches extracted\n",
    "# around each corner point from both images\n",
    "patch_size=15\n",
    "npts1=x1.shape[0]\n",
    "npts2=x2.shape[0]\n",
    "patches1=np.zeros((patch_size, patch_size, npts1))\n",
    "patches2=np.zeros((patch_size, patch_size, npts2))\n",
    "\n",
    "# The following part extracts the patches using bilinear interpolation\n",
    "k=(patch_size-1)/2.\n",
    "xv,yv=np.meshgrid(np.arange(-k,k+1),np.arange(-k, k+1))\n",
    "for i in range(npts1):\n",
    "    patch = map_coordinates(I1, (yv + y1[i], xv + x1[i]))\n",
    "    patches1[:,:,i] = patch\n",
    "for i in range(npts2):\n",
    "    patch = map_coordinates(I2, (yv + y2[i], xv + x2[i]))\n",
    "    patches2[:,:,i] = patch\n",
    "\n",
    "############################ SSD MEASURE ######################################    \n",
    "# Compute the sum of squared differences (SSD) of pixels' intensities\n",
    "# for all pairs of patches extracted from the two images\n",
    "distmat = np.zeros((npts1, npts2))\n",
    "for i1 in range(npts1):\n",
    "    for i2 in range(npts2):\n",
    "        distmat[i1,i2]=np.sum((patches1[:,:,i1]-patches2[:,:,i2])**2)\n",
    "\n",
    "# Next we compute pairs of patches that are mutually nearest neighbors\n",
    "# according to the SSD measure\n",
    "ss1 = np.amin(distmat, axis=1)\n",
    "ids1 = np.argmin(distmat, axis=1)\n",
    "ss2 = np.amin(distmat, axis=0)\n",
    "ids2 = np.argmin(distmat, axis=0)\n",
    "\n",
    "pairs = []\n",
    "for k in range(npts1):\n",
    "    if k == ids2[ids1[k]]:\n",
    "        pairs.append(np.array([k, ids1[k], ss1[k]]))\n",
    "pairs = np.array(pairs)\n",
    "\n",
    "# Sort the mutually nearest neighbors based on the SSD\n",
    "sorted_ssd = np.sort(pairs[:,2], axis=0) # SSD measures sorted in ascending order\n",
    "id_ssd = np.argsort(pairs[:,2], axis=0)  # row indeces sorted by order of SSD measure \n",
    "sorted_pairs_ssd = pairs[id_ssd]         # pairs sorted by SSD measure\n",
    "\n",
    "############################ END OF SSD MEASURE ################################  \n",
    "\n",
    "\n",
    "# Visualize the 40 best matches which are mutual nearest neighbors\n",
    "# and have the smallest SSD values\n",
    "Nvis = 40\n",
    "montage = np.concatenate((I1, I2), axis=1)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.suptitle(\"The best 40 matches according to SSD measure\", fontsize=20)\n",
    "plt.imshow(montage, cmap='gray')\n",
    "plt.title('The best 40 matches')\n",
    "for k in range(np.minimum(len(sorted_pairs_ssd), Nvis)):\n",
    "    p1_idx = int(sorted_pairs_ssd[k,0])\n",
    "    p2_idx = int(sorted_pairs_ssd[k,1])\n",
    "    plt.plot(x1[p1_idx], y1[p1_idx], 'rx')\n",
    "    plt.plot(x2[p2_idx] + I1.shape[1], y2[p2_idx], 'rx')\n",
    "    plt.plot([x1[p1_idx], x2[p2_idx]+I1.shape[1]], \n",
    "         [y1[p1_idx], y2[p2_idx]])\n",
    "plt.show()\n",
    "    \n",
    "# Calculate the number of correct matches\n",
    "# First, estimate the geometric transformation between images\n",
    "src=[]\n",
    "dst=[]\n",
    "for k in range(len(sorted_pairs_ssd)):\n",
    "    src.append([x1[int(sorted_pairs_ssd[k, 0])], y1[int(sorted_pairs_ssd[k, 0])]])\n",
    "    dst.append([x2[int(sorted_pairs_ssd[k, 1])], y2[int(sorted_pairs_ssd[k, 1])]])\n",
    "src=np.array(src)\n",
    "dst=np.array(dst)\n",
    "rthrs=2\n",
    "tform,_ = ransac((src, dst), ProjectiveTransform, min_samples=4,\n",
    "                               residual_threshold=rthrs, max_trials=1000)\n",
    "H1to2p = tform.params    \n",
    "    \n",
    "# Then, check that how many of the nearest neighbor matches actually\n",
    "# are correct correspondences\n",
    "p1to2=np.dot(H1to2p, np.hstack((src, np.ones((src.shape[0],1)))).T)\n",
    "p1to2 = p1to2[:2,:] / p1to2[2,:]\n",
    "p1to2 = p1to2.T\n",
    "pdiff=np.sqrt(np.sum((dst-p1to2)**2, axis=1))\n",
    "\n",
    "# The criterion for the match being a correct is that its correspondence in\n",
    "# the second image should be at most rthrs=2 pixels away from the transformed\n",
    "# location\n",
    "n_correct = len(pdiff[pdiff<rthrs])\n",
    "print(\"{} correct matches.\".format(n_correct))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "56c28f1a9605cbbab6ad7b9f2e2fdeaa",
     "grade": false,
     "grade_id": "cell-52b120b8eef6495b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 1.4. Matching using normalized cross-correlation (NCC)\n",
    "\n",
    "#### Task:\n",
    "Implement matching of mutual nearest neighbors using **normalized cross-correlation (NCC)** instead of SSD.\n",
    "\n",
    "For two image patches \\(f\\) and \\(g\\) of the same size, NCC is\n",
    "<center>$\\text{NCC}(f,g) = \\frac{\\sum_{k,l}(g(k,l)-\\bar{g})(f(k,l)-\\bar{f})}{\\sqrt{\\sum_{k,l}(g(k,l)-\\bar{g})^{2}\\sum_{k,l}(f(k,l)-\\bar{f})^{2}}}$</center>\n",
    "\n",
    "where $\\bar{g}$ and $\\bar{f}$ are the mean intensity values of patches $g$ and $f$. The values of NCC are\n",
    "always between -1 and 1, and **the larger** the value **the more similar** the patches are.<br><br>\n",
    "\n",
    "\n",
    "#### Hint:\n",
    "Start from the SSD implementation:\n",
    "- Copy SSD MEASURE codes above\n",
    "- Modify the lines performing the `distmat` calculation from SSD to NCC\n",
    "- Determine mutual matches by **maximizing** NCC (SSD used minimization)\n",
    "- Sort matches in **descending** NCC order (SSD used ascending)\n",
    "\n",
    "### Important:\n",
    "- Store the sorted matches in a variable named `sorted_pairs_ncc`.\n",
    "- `sorted_pairs_ncc` must be a **NumPy array** of shape `(m, 3)` where:\n",
    "  - **Column 0**: integer index in `patches1`\n",
    "  - **Column 1**: integer index in `patches2`\n",
    "  - **Column 2**: float NCC score\n",
    "- The matches must be **sorted in descending order of NCC score**  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "522eecc033e359370982bcb1537652cd",
     "grade": false,
     "grade_id": "cell-a3f04020756d63ae",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "############################ NCC MEASURE ###################################### \n",
    "\n",
    "##-your-code-starts-here-##\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "##-your-code-ends-here-##\n",
    "\n",
    "############################ END OF NCC MEASURE ###############################   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab7465164c4e2cb71cee275ff06e6833",
     "grade": false,
     "grade_id": "cell-1439904f911b7612",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize the 40 best matches which are mutual nearest neighbors\n",
    "# and have the smallest SSD values\n",
    "Nvis = 40\n",
    "montage = np.concatenate((I1, I2), axis=1)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.suptitle(\"The best 40 matches according to NCC measure\", fontsize=20)\n",
    "plt.imshow(montage, cmap='gray')\n",
    "plt.title('The best 40 matches')\n",
    "for k in range(np.minimum(len(sorted_pairs_ncc), Nvis)):\n",
    "    p1_idx = int(sorted_pairs_ncc[k,0])\n",
    "    p2_idx = int(sorted_pairs_ncc[k,1])\n",
    "    plt.plot(x1[p1_idx], y1[p1_idx], 'rx')\n",
    "    plt.plot(x2[p2_idx] + I1.shape[1], y2[p2_idx], 'rx')\n",
    "    plt.plot([x1[p1_idx], x2[p2_idx]+I1.shape[1]], \n",
    "         [y1[p1_idx], y2[p2_idx]])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c9e30313262666f257afc6b55e7d452b",
     "grade": true,
     "grade_id": "cell-b006abe69db63f2a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visible tests for the NCC measure\n",
    "\n",
    "# Existence, type and shape\n",
    "assert 'sorted_pairs_ncc' in globals(), \"You must define `sorted_pairs_ncc`.\"\n",
    "assert isinstance(sorted_pairs_ncc, np.ndarray), \"`sorted_pairs_ncc` must be a NumPy array.\"\n",
    "assert sorted_pairs_ncc.ndim == 2 and sorted_pairs_ncc.shape[1] == 3, \"`sorted_pairs_ncc` must have shape (m, 3).\"\n",
    "\n",
    "# NCC range (allow tiny numeric slack)\n",
    "if sorted_pairs_ncc.shape[0] > 0:\n",
    "    ncc_vals = sorted_pairs_ncc[:, 2]\n",
    "    assert np.all(ncc_vals <= 1.0001) and np.all(ncc_vals >= -1.0001), \"NCC values must lie in [-1, 1].\"\n",
    "\n",
    "print(\"All visible tests passed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5b53297a7ee6e84033a152fa6f248b35",
     "grade": true,
     "grade_id": "cell-ac1b2298c6168a13",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HIDDEN TEST CELL\n",
    "# This cell contains hidden test cases that will be evaluated after the deadline.\n",
    "# Please do not remove or modify this cell, as it is required for grading.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Number of correct correspondences with NCC\n",
    "\n",
    "#### Task\n",
    "Compute how many of the matched pairs from your NCC implementation are correct correspondences.\n",
    "\n",
    "#### Hint\n",
    "You can reuse the transformation estimation and correctness check code from the SSD section, with minimal modifications.\n",
    "\n",
    "#### Important\n",
    "- Store the result in a variable named `n_correct`.  \n",
    "- A match is considered correct if its correspondence in the second image is within **2 pixels** of the projected location (using the estimated transformation). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a2f1ab5ab91865526c70d673371fa125",
     "grade": false,
     "grade_id": "cell-55a008a902cbc6e4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##-your-code-starts-here-##\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "##-your-code-ends-here-##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "22398e5f17b7740392a1fb073c1113ef",
     "grade": true,
     "grade_id": "cell-bd63b5c34a559bc9",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visible tests for the number of correct matches\n",
    "\n",
    "# Check variable existence\n",
    "assert 'n_correct' in globals(), \"Variable 'n_correct' is not defined. Please store your result in 'n_correct'.\"\n",
    "\n",
    "# Check value constraints\n",
    "assert (n_correct > 0) and (n_correct != 67), \"'n_correct' must be positive and different from the SSD result.\"\n",
    "\n",
    "print(\"All visible test passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b8270057bc3cead1c7506f03e0e197ad",
     "grade": true,
     "grade_id": "cell-0164b27a607b3b62",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HIDDEN TEST CELL\n",
    "# This cell contains hidden test cases that will be evaluated after the deadline.\n",
    "# Please do not remove or modify this cell, as it is required for grading.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e7009755fe26ecb5db3e7cee82ed2bc9",
     "grade": false,
     "grade_id": "cell-905ed3639e5862ea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 1.6. Answer the question below\n",
    "\n",
    "Which  one  of  the  two  similarity  measures  performs  better  in  this  case  and  why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a117f4b82c1a4baf6d22e6156dac2b95",
     "grade": true,
     "grade_id": "ssd_or_ncc_and_why",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "347591b15ae07c831ea190c646f87d24",
     "grade": false,
     "grade_id": "cell-571d350721cb977e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Exercise 2 - Matching SURF regions\n",
    "SURF (Speeded up robust features) is quite similar to SIFT, which was presented in the lecture. In this implementation, the descriptor vectors for the local regions have 64 elements (instead of 128 in SIFT), but\n",
    "Euclidean distance can still be used as a similarity measure in descriptor space. \n",
    "\n",
    "The exercise begins by displaying the matches using **nearest neighbor distance** (code for this is already provided). Your task is to sort the given nearest neighbor matches in ascending order based on the **nearest\n",
    "neighbor distance ratio (NNDR)**.\n",
    "\n",
    "### Steps:\n",
    "\n",
    "- **2.1.** SURF features and similarity transformation with OpenCV and scikit image libraries\n",
    "- **2.2.** Matching and sorting by nearest neighbor distance\n",
    "- **2.3.** Sorting matches by the nearest neighbor distance ratio (NNDR)\n",
    "- **2.4.** Answer the questions\n",
    "\n",
    "Familiarize yourself with the provided code in **2.1** and **2.2**, complete the task in **2.3**, and answer the question in **2.4**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. SURF features and similarity transformation with OpenCV and scikit image libraries\n",
    "\n",
    "This part illustrates OpenCV's built-in brute force matcher. SURF regions are extracted and matched and a similarity transformation (i.e. rotation, translation and scale) between the views is estimated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "22a3c31576c885eb26423559d51280d8",
     "grade": false,
     "grade_id": "cell-092859eabefa0f95",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "img1 = np.array(Image.open(data_dir+'boat1.png'))\n",
    "img2 = np.array(Image.open(data_dir+'boat6.png'))\n",
    "\n",
    "# Initiate SURF detector\n",
    "surf = cv2.xfeatures2d.SURF_create(extended=False)\n",
    "# Find the keypoints and descriptors with SURF detector\n",
    "kp1, desc1 = surf.detectAndCompute(img1, None)\n",
    "kp2, desc2 = surf.detectAndCompute(img2, None)\n",
    "kps1 = np.array([p.pt for p in kp1])\n",
    "kps2 = np.array([p.pt for p in kp2])\n",
    "kps1_rad = np.array([p.size / 2 for p in kp1]) #rad==scale\n",
    "kps2_rad = np.array([p.size / 2 for p in kp2])\n",
    "\n",
    "# Initiate BruteForce matcher with default params\n",
    "bf = cv2.BFMatcher()\n",
    "# Perform matching and save k=1 nearest neighbors for each descriptor\n",
    "matches = bf.knnMatch(desc1, desc2, k=1)\n",
    "# The candidate point matches can be visualized as follows:\n",
    "img3 = cv2.drawMatchesKnn(img1,kp1,img2,kp2,matches,None,flags=2)\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.suptitle('Feature matching using SURF', fontsize=20)\n",
    "plt.imshow(img3)\n",
    "plt.title('Candidate point matches')\n",
    "plt.show()\n",
    "\n",
    "## The estimation of geometric transformations is covered later in lectures\n",
    "## but it can be done as follows using scikit-image Python library:\n",
    "# Collect feature points and scales from the match objects\n",
    "source_pts = []\n",
    "target_pts = []\n",
    "\n",
    "for match in matches:\n",
    "    # Collect feature point coords and scale query (img1)\n",
    "    x, y = kp1[match[0].queryIdx].pt \n",
    "    source_pts.append(np.array([x, y]))  \n",
    "    # Collect feature point coords and scale query (img2)\n",
    "    x, y = kp2[match[0].trainIdx].pt\n",
    "    target_pts.append(np.array([x, y]))\n",
    "    \n",
    "source_pts = np.array(source_pts)\n",
    "target_pts = np.array(target_pts)\n",
    "\n",
    "## Estimate the geometric transformation between images\n",
    "rthrs=10\n",
    "tform, inliers = ransac((source_pts, target_pts), SimilarityTransform, min_samples=2,\n",
    "                               residual_threshold=rthrs, max_trials=1000)\n",
    "H1to2p = tform.params\n",
    "\n",
    "s_in = source_pts[inliers,:]\n",
    "t_in = target_pts[inliers,:]\n",
    "\n",
    "source_pts_aug = np.hstack((s_in,np.ones((s_in.shape[0],1))))\n",
    "target_pts_aug = np.hstack((t_in,np.ones((t_in.shape[0],1))))\n",
    "\n",
    "target_ = np.dot(H1to2p,source_pts_aug.T)\n",
    "target_ = target_[:2,:] / target_[2,:]\n",
    "target_ = target_.T\n",
    "\n",
    "xv, yv = np.meshgrid(np.arange(0,img1.shape[1]), np.arange(0,img1.shape[0]))\n",
    "src_all = np.vstack((xv.flatten(), yv.flatten(), np.ones((1, xv.size))))\n",
    "target_all = np.dot(H1to2p, src_all)\n",
    "target_all_ = target_all[:2,:] / target_all[2,:]\n",
    "xvt = target_all_[0,:].reshape(xv.shape[0], xv.shape[1])\n",
    "yvt = target_all_[1,:].reshape(yv.shape[0], yv.shape[1])\n",
    "img2t = map_coordinates(img2, (yvt, xvt))\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(16,8))\n",
    "ax = axes.ravel()\n",
    "ax[0].imshow(img1, cmap='gray')\n",
    "ax[0].set_title(\"Input Image 1\")\n",
    "ax[1].imshow(img2t, cmap='gray')\n",
    "ax[1].set_title(\"Transformed Image 2\")\n",
    "ax[2].imshow(np.abs(img1-img2t), cmap='gray')\n",
    "ax[2].set_title(\"Difference image after geometric registration\")\n",
    "\n",
    "matches_in = list(compress(matches, inliers))\n",
    "img3 = cv2.drawMatchesKnn(img1,kp1,img2,kp2,matches_in,None,flags=2)\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.imshow(img3)\n",
    "plt.title(\"Matched inlier points\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2228fd1e33e2f3e4442a13f5de7607f6",
     "grade": false,
     "grade_id": "cell-0042003848ade397",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 2.2. Matching and sorting by nearest neighbor distance\n",
    "\n",
    "This example demonstrates nearest-neighbor matching between feature vectors in `desc1` and `desc2`.  \n",
    "It computes the pairwise distances, identifies the mutually nearest neighbors,  \n",
    "and then sorts them by distance to visualize the top 5 matches.\n",
    "\n",
    "You can use this as a reference when implementing the NNDR-based matching in Step 2.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "78e9374cd5c416e03013c58f3c38b33c",
     "grade": false,
     "grade_id": "cell-b253ea706d48783f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Let's start by computing the pairwise distances of feature vectors to matrix 'distmat'\n",
    "## you can use the for-loop version or faster vectorized version\n",
    "#distmat = np.zeros((desc1.shape[0], desc2.shape[0]))\n",
    "#for i in range(desc1.shape[0]):\n",
    "#    for j in range(desc2.shape[0]):\n",
    "#        distmat[i,j] = np.linalg.norm(desc1[i,:] - desc2[j,:])\n",
    "## Vectorized version: sqrt(xTx + yTy - 2xTy)\n",
    "distmat = np.dot(desc1, desc2.T)\n",
    "X_terms = np.expand_dims(np.diag(np.dot(desc1, desc1.T)), axis=1)\n",
    "X_terms = np.tile(X_terms,(1,desc2.shape[0]))\n",
    "Y_terms = np.expand_dims(np.diag(np.dot(desc2, desc2.T)), axis=0)\n",
    "Y_terms = np.tile(Y_terms,(desc1.shape[0],1))\n",
    "distmat = np.sqrt(Y_terms + X_terms - 2*distmat)\n",
    "\n",
    "## We determine the mutually nearest neighbors\n",
    "dist1 = np.amin(distmat, axis=1)\n",
    "ids1 = np.argmin(distmat, axis=1)\n",
    "dist2 = np.amin(distmat, axis=0)\n",
    "ids2 = np.argmin(distmat, axis=0)\n",
    "\n",
    "pairs = []\n",
    "for k in range(ids1.size):\n",
    "    if k == ids2[ids1[k]]:\n",
    "        pairs.append(np.array([k, ids1[k], dist1[k]]))\n",
    "pairs = np.array(pairs)\n",
    "\n",
    "# We sort the mutually nearest neighbors based on the distance \n",
    "id_nnd = np.argsort(pairs[:,2], axis=0)\n",
    "pairs_nnd = pairs[id_nnd]\n",
    "pairs_nnd = pairs_nnd[:,:2] # only two first columns are needed  \n",
    "\n",
    "# We visualize the 5 best matches \n",
    "Nvis = 5\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.suptitle(\"Top 5 mutual nearest neigbors of SURF features\", fontsize=20)\n",
    "plt.imshow(np.hstack((img1, img2)), cmap='gray')\n",
    "\n",
    "t = np.arange(0, 2*np.pi, 0.1)\n",
    "\n",
    "# Display matches\n",
    "for k in range(Nvis):\n",
    "    pid1 = pairs_nnd[k, 0]\n",
    "    pid2 = pairs_nnd[k, 1]\n",
    "    \n",
    "    loc1 = kps1[int(pid1)]\n",
    "    r1 = 6*kps1_rad[int(pid1)]\n",
    "    loc2 = kps2[int(pid2)]\n",
    "    r2 = 6*kps2_rad[int(pid2)]\n",
    "    \n",
    "    plt.plot(loc1[0]+r1*np.cos(t), loc1[1]+r1*np.sin(t), 'm-', linewidth=3)\n",
    "    plt.plot(loc2[0]+r2*np.cos(t)+img1.shape[1], loc2[1]+r2*np.sin(t), 'm-', linewidth=3)\n",
    "    plt.plot([loc1[0], loc2[0]+img1.shape[1]], [loc1[1], loc2[1]], 'c-')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c2241205f3b10d45dd0e405e6056d91a",
     "grade": false,
     "grade_id": "cell-899b13e4a69b69d7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 2.3. Sorting matches by the nearest neighbor distance ratio (NNDR)\n",
    "\n",
    "#### Task:\n",
    "Sort the given nearest neighbor matches in ascending order based on\n",
    "the **nearest neighbor distance ratio (NNDR)**, which is defined as:\n",
    "<center>$\\text{NNDR} = \\frac{d_1}{d_2} = \\frac{||D_A - D_B ||}{||D_A - D_C ||}$</center> \n",
    "where $d_1$ and $d_2$ are the distances to the nearest and second-nearest neighbors, respectively. $D_A$ is the descriptor from the target image, and $D_B$ and $D_C$ are its closest two descriptors in the other image (see Equation 4.18 in the course book.)\n",
    "\n",
    "#### Hint:\n",
    "- `pairs`, `distmat`, and `distmat_sorted` have already been computed in the previous step of this exercise or are provided here.\n",
    "- Loop through the first column in `pairs` (indices of features from the first image).\n",
    "- For each index, get the corresponding row from `distmat_sorted`.\n",
    "- Take the **nearest** and **second-nearest** distances from that row to compute the NNDR.\n",
    "- Store each NNDR value in the array `nndr`.\n",
    "- Sort the matches by **ascending NNDR** \n",
    "\n",
    "### Important:\n",
    "- Store the sorted matches in a variable named `pairs_nndr`.\n",
    "- `pairs_nndr` must be a NumPy array of shape `(m, 2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "311c96b987c5276c490d8c238b75ac92",
     "grade": false,
     "grade_id": "cell-ace36b64bc50d47c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "distmat_sorted = np.sort(distmat, axis=1)  # each row sorted in ascending order\n",
    "nndr=np.zeros(pairs.shape[0])  # pre-allocate memory\n",
    "\n",
    "##-your-code-starts-here-##\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "##-your-code-ends-here-##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8755b03d573c26ab011760c78b782fc2",
     "grade": false,
     "grade_id": "cell-81e80121a190a75d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize the 5 best matches\n",
    "Nvis = 5\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.suptitle(\"SURF matching with NNDR\", fontsize=20)\n",
    "plt.imshow(np.hstack((img1, img2)), cmap='gray')\n",
    "plt.title('Top 5 mutual nearest neighbors of SURF features')\n",
    "\n",
    "# Display matches\n",
    "t = np.arange(0, 2*np.pi, 0.1)\n",
    "for k in range(Nvis):\n",
    "    pid1 = pairs_nndr[k, 0]\n",
    "    pid2 = pairs_nndr[k, 1]\n",
    "    \n",
    "    loc1 = kps1[int(pid1)]\n",
    "    r1 = 6*kps1_rad[int(pid1)]\n",
    "    loc2 = kps2[int(pid2)]\n",
    "    r2 = 6*kps2_rad[int(pid2)]\n",
    "    \n",
    "    plt.plot(loc1[0]+r1*np.cos(t), loc1[1]+r1*np.sin(t), 'm-', linewidth=3)\n",
    "    plt.plot(loc2[0]+r2*np.cos(t)+img1.shape[1], loc2[1]+r2*np.sin(t), 'm-', linewidth=3)\n",
    "    plt.plot([loc1[0], loc2[0]+img1.shape[1]], [loc1[1], loc2[1]], 'c-')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4934e24f9a9451b37311481a1ce0c45d",
     "grade": false,
     "grade_id": "cell-2fbab92188533f49",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visible tests\n",
    "\n",
    "# Check that pairs_nndr exists\n",
    "assert 'pairs_nndr' in globals(), \"`pairs_nndr` is not defined.\"\n",
    "\n",
    "# Check type and shape\n",
    "assert isinstance(pairs_nndr, np.ndarray), \"`pairs_nndr` must be a NumPy array.\"\n",
    "assert pairs_nndr.ndim == 2 and pairs_nndr.shape[1] == 2, \"`pairs_nndr` must have shape (m, 2).\"\n",
    "\n",
    "print(\"All visible tests passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "585b81af76488798035ed3be105aaa4b",
     "grade": true,
     "grade_id": "cell-44c3b2f77d86e078",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HIDDEN TEST CELL\n",
    "# This cell contains hidden test cases that will be evaluated after the deadline.\n",
    "# Please do not remove or modify this cell, as it is required for grading.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4a675b5cb20ffe5ae290fb801c2e5649",
     "grade": false,
     "grade_id": "cell-c2a48056ae57ecc5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 2.4. Answer the questions below\n",
    "\n",
    "1. Which one of the two similarity measures performs better in this case and why?\n",
    "\n",
    "2. How many of the top 5 matches are correct correspondences for each of the two similarity measures?\n",
    "\n",
    "3. What are the benefits of using SURF regions instead of Harris corners? \n",
    "\n",
    "4. Why the matching approach of Exercise 1 (i.e. Harris corners and NCC based matching) would not work for the example images of Exercise 2?\n",
    "\n",
    "5. In what kind of cases Harris corners may still be better than SURF and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "92b27c3a43e81c041993829bab9a3f25",
     "grade": true,
     "grade_id": "surf_manual",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8e97ab0b1dacf6825baf9656719d4e7d",
     "grade": false,
     "grade_id": "cell-b46dff326d72b17f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Exercise 3 - Scale-space blob detection\n",
    "  \n",
    "**Your task is to implement the missing parts of a scale-space blob detector**. We will use SIFT features to estimate a similarity transform between the two images and then check whether the regions around detected blobs correspond across the images. \n",
    "\n",
    "### Steps:\n",
    "\n",
    "- **3.1.** SIFT detection and matching\n",
    "- **3.2.** Scale-space blob detector\n",
    "- **3.3.** Visualise detected blobs\n",
    "- **3.4.** Illustrate detected regions of blobs with high overlap\n",
    "\n",
    "Familiarize yourself with the provided code in **3.1**, complete the task in **3.2**, and review the illustrations in **3.3** and **3.4**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "87a7f4b38ba0f5ca6eceae0ba3ddb2b3",
     "grade": false,
     "grade_id": "cell-a16ffb90e5be867c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 3.1 SIFT detection and matching\n",
    "\n",
    "This example demonstrates SIFT feature detection and matching using OpenCV. In **Step 3.4**, the matches are used to estimate a similarity transform between the images; we then compare the blob regions detected in **Step 3.2** and visualise the overlapping regions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8a91e81b80cdc9be2695c8ea8e7d5d6d",
     "grade": false,
     "grade_id": "cell-b2e31bab03ec2a25",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load images\n",
    "img1 = np.array(Image.open(data_dir+'boat1.png'))\n",
    "img2 = np.array(Image.open(data_dir+'boat6.png'))\n",
    "\n",
    "# Initiate SIFT detector\n",
    "sift = cv2.SIFT_create()\n",
    "# Find the keypoints and descriptors with SIFT detector\n",
    "kp1, desc1 = sift.detectAndCompute(img1, None)\n",
    "kp2, desc2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "# Initiate BruteForce matcher with default params\n",
    "bf = cv2.BFMatcher()\n",
    "# Perform matching and save k=2 nearest neighbors for each descriptor\n",
    "matches = bf.knnMatch(desc1, desc2, k=2)\n",
    "# Apply Lowe's ratio test\n",
    "good_matches = []\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.75*n.distance:\n",
    "        good_matches.append(m)\n",
    "# Sort matches \n",
    "good_matches = sorted(good_matches, key = lambda x:x.distance)\n",
    "# Collect feature points and scales from the match objects\n",
    "source_pts = []\n",
    "target_pts = []\n",
    "source_radii = []\n",
    "target_radii = []\n",
    "\n",
    "for match in good_matches:\n",
    "    # Collect feature point coords and scale query (img1)\n",
    "    x, y = kp1[match.queryIdx].pt\n",
    "    pt = np.array([np.round(x), np.round(y)]).astype(int)\n",
    "    source_pts.append(pt)\n",
    "    radius = kp1[match.queryIdx].size / 2.\n",
    "    source_radii.append(radius)\n",
    "    \n",
    "    # Collect feature point coords and scale query (img2)\n",
    "    x, y = kp2[match.trainIdx].pt\n",
    "    pt = np.array([np.round(x), np.round(y)]).astype(int)\n",
    "    target_pts.append(pt)\n",
    "    radius = kp2[match.trainIdx].size / 2.\n",
    "    target_radii.append(radius)\n",
    "    \n",
    "source_pts = np.array(source_pts)\n",
    "source_radii = np.array(source_radii)\n",
    "target_pts = np.array(target_pts)\n",
    "target_radii = np.array(target_radii)\n",
    "\n",
    "\n",
    "# Plot \n",
    "montage = np.concatenate((img1, img2), axis=1)\n",
    "Nvis = 20\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.suptitle(\"Matching points using SIFT\", fontsize=20)\n",
    "plt.imshow(montage, cmap='gray')\n",
    "plt.title('The best {} matches'.format(Nvis))\n",
    "for k in range(0, Nvis):   \n",
    "    plt.plot([source_pts[k,0], target_pts[k,0]+img1.shape[1]],\\\n",
    "             [source_pts[k,1], target_pts[k,1]], 'r-')\n",
    "    \n",
    "    x,y=circle_points(source_pts[k,0], source_pts[k,1],\\\n",
    "                      3*np.sqrt(2)*source_radii[k])\n",
    "    plt.plot(x, y, 'r', linewidth=1.5)\n",
    "    \n",
    "    x,y=circle_points(target_pts[k,0]+img1.shape[1], target_pts[k,1],\\\n",
    "                      3*np.sqrt(2)*target_radii[k])\n",
    "    plt.plot(x, y, 'r', linewidth=1.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a69811b5da7ba51ada8fc1702762ca5d",
     "grade": false,
     "grade_id": "cell-c2385c8113cb2166",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 3.2 Scale-space blob detector \n",
    "\n",
    "#### Task\n",
    "Implement the missing part of the `scaleSpaceBlobs` function: filter the image with the scale-normalized Laplacian of Gaussian at each scale `i`, and store the square of the Laplacian response in `scalespace[:,:,i]`.\n",
    "\n",
    "#### Outline of the scale-space blob detector\n",
    "1. Generate a Laplacian of Gaussian filter (start with $\\sigma = 0.5$).  \n",
    "2. Build the Laplacian scale space for *n* iterations:  \n",
    "   - **Filter the image with the scale-normalized Laplacian at the current scale.**  \n",
    "   - **Save the square of the Laplacian response for the current level in `scalespace[:,:,i]`.**  \n",
    "   - Increase the scale by a factor *k*.  \n",
    "3. Perform non-maximum suppression in scale space.  \n",
    "4. Display the resulting circles at their characteristic scales.  \n",
    "\n",
    "\n",
    "#### Important:\n",
    "-  Use values k = 1.19 and n = 18\n",
    "-  This task corresponds to Exercise 4.1 in the course book. A similar assignment\n",
    "has been used by Lazebnik at UIUC and their course page gives also more detailed\n",
    "instructions: http://slazebni.cs.illinois.edu/spring16/assignment2.html.\n",
    "- You can check in Step 3.3 that the output is similar to pre-computed blobs. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "afe3eeb351dabef440eb5852140498bc",
     "grade": false,
     "grade_id": "cell-dba4228acd97ed9c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scaleSpaceBlobs(img, N):\n",
    "    start = time.time()\n",
    "    \n",
    "    sigma0 = 0.5      # The first sigma to start with\n",
    "    k = 1.19          # \n",
    "    Nscales = 18      # Number of scales in scalespace\n",
    "    \n",
    "    # Pre-allocate memory for the scale space, sigmas and filtered images\n",
    "    scalespace = np.zeros((img.shape[0], img.shape[1], Nscales))\n",
    "    sigmas = np.zeros(Nscales)\n",
    "    Lxx = np.zeros(img.shape)\n",
    "    Lyy = np.zeros(img.shape)\n",
    "    \n",
    "    # Create a scalespace by...\n",
    "    print(\"Creating a scalespace...\")\n",
    "    for i in range(Nscales):\n",
    "        # Get the current sigma and generate Gaussian filters.\n",
    "        # g is the 2D Gaussian filter, and gxx and gyy are the \n",
    "        # second derivatives of the Gaussian with respect to x and y,\n",
    "        # respectively\n",
    "        sigmas[i] = (k ** i) * sigma0\n",
    "        g,_,_,gxx,gyy,_, = gaussian2(sigmas[i])\n",
    "\n",
    "        # Filter the image with the scale-normalized Laplacian of Gaussian\n",
    "        # at each scale i, and store the result in the variable scalespace[:,:,i]\n",
    "        \n",
    "        ##-your-code-starts-here-##\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        ##-your-code-ends-here-##\n",
    "        scalespace[:,:,i] = (sigmas[i]**2 * (Lxx + Lyy))**2\n",
    "        \n",
    "        \n",
    "    # Selection of local maxima, each maxima defines a circular region.\n",
    "    \n",
    "    print(\"Calculating local maxima...\")\n",
    "    # Pre-allocate memory for the local maxima images\n",
    "    localmaxima = np.zeros(scalespace.shape)\n",
    "    # Filter shape for calculating the local maxima\n",
    "    footprint = np.ones((3,3))\n",
    "    footprint[1,1] = 0\n",
    "    for i in range(Nscales):\n",
    "        # Calculate local maxima\n",
    "        maxi = maximum_filter(scalespace[:,:,i], footprint=footprint, mode='constant')\n",
    "        # test if pixel values are larger than neighborhood\n",
    "        localmaxima[:,:,i] = scalespace[:,:,i] > maxi  \n",
    "      \n",
    "    # In the end each row in 'blobs' encodes one circular region as follows:.\n",
    "    # [x, y, r, filter_response]\n",
    "    # where x and y are the column and row coordinates of the circle center,\n",
    "    # r is the radius of the circle, r=sqrt(2)*sigma (see slides of Lecture 3)\n",
    "    # last column indicates the response of the Laplacian of Gaussian filter\n",
    "    blobs = None\n",
    "    # Pre-allocate memory for consecutive scales\n",
    "    scaleA = np.zeros(img.shape)\n",
    "    scaleB = np.zeros(img.shape)\n",
    "    scaleC = np.zeros(img.shape)\n",
    "    \n",
    "    print(\"Calculating detections...\")\n",
    "    for i in range(1,Nscales-1):\n",
    "        # Consecutive scales\n",
    "        scaleA = scalespace[:,:,i-1]\n",
    "        scaleB = scalespace[:,:,i]\n",
    "        scaleC = scalespace[:,:,i+1]\n",
    "        # Indices of local maxima\n",
    "        ri, ci = np.nonzero(localmaxima[:,:,i])        \n",
    "        # Compare the current level to the previous and next level\n",
    "        idmax = np.nonzero((scaleA[ri,ci] < scaleB[ri,ci]) & (scaleC[ri,ci] < scaleB[ri,ci]))[0]\n",
    "        rlmax = ri[idmax]\n",
    "        clmax = ci[idmax]\n",
    "        # Add blob coordinates, circle radiuses and filter responses to 'blobs'\n",
    "        if blobs is not None:\n",
    "            tmp = np.vstack((clmax, rlmax, \n",
    "                      np.sqrt(2)*sigmas[i]*np.ones(len(rlmax)), \n",
    "                      scaleB[rlmax, clmax])).T\n",
    "            blobs = np.vstack((blobs, tmp))\n",
    "        else:\n",
    "            blobs = np.vstack((clmax, rlmax, \n",
    "                      np.sqrt(2)*sigmas[i]*np.ones(len(rlmax)), \n",
    "                      scaleB[rlmax, clmax])).T\n",
    "\n",
    "    # Sort the blobs according to the response of Laplacian of Gaussian.\n",
    "    # Return N best detections.\n",
    "    ids = np.argsort(blobs[:,3])\n",
    "    sblobs = np.flipud(blobs[ids, :])\n",
    "    blobsN = sblobs[0:min(N, sblobs.shape[0]), :]\n",
    "    # Ouput the execution time\n",
    "    print(\"Total time elapsed (s): \" + str(time.time() - start) + \"\\n\")\n",
    "\n",
    "    return blobsN, scalespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "adae11772b469744d08efb9550486984",
     "grade": true,
     "grade_id": "cell-0c90c6c7665d2369",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HIDDEN TEST CELL\n",
    "# This cell contains hidden tests for grading after the deadline.\n",
    "# Please do not remove or modify this cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e1ea9a4667e390e381d854d9960076b",
     "grade": true,
     "grade_id": "cell-059f349aaf5b8b6e",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HIDDEN TEST CELL\n",
    "# This cell contains hidden tests for grading after the deadline.\n",
    "# Please do not remove or modify this cell.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c01545f82eb56f36961d22be87758fa9",
     "grade": false,
     "grade_id": "cell-83e6da77e532c958",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 3.3 Visualise detected blobs\n",
    "\n",
    "Run the cell below to compute the N strongest blob candidates with `scaleSpaceBlobs`function for each image, and visualise the top detections as circles at their characteristic scales overlaid on each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef79c0d6d4090ef0c7ef9ebd102f5303",
     "grade": false,
     "grade_id": "cell-438a1365632cff2f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Each row in 'blobs1' and 'blobs2' defines a circular region as follows:  \n",
    "# [x y r filter_response]\n",
    "# here x and y are the column and row coordinates of the circle center\n",
    "# r is the radius of the circle, r=sqrt(2)*sigma (see slide 77 of Lecture 3)\n",
    "# last column indicates the response of the Laplacian of Gaussian filter\n",
    "\n",
    "# Below N is the number of strongest blobs that are returned.\n",
    "# (strongest local maxima for the scale-normalized Laplacian of Gaussian)\n",
    "# Apply your scaleSpaceBlobs function.\n",
    "N=500;\n",
    "blobs1, scalespace1 = scaleSpaceBlobs(img1, N)\n",
    "blobs2, scalespace2 = scaleSpaceBlobs(img2, N)\n",
    "\n",
    "\n",
    "# Show detected blob features\n",
    "NVIS=150;\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16,8))\n",
    "plt.suptitle(f\"Showing {NVIS} of {len(blobs1)} detected blobs\", fontsize=20)\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(img1, cmap='gray')\n",
    "ax[1].imshow(img2, cmap='gray')\n",
    "for k in range(0, NVIS):\n",
    "    x, y = circle_points(blobs1[k,0], blobs1[k,1], 3*np.sqrt(2)*blobs1[k,2])\n",
    "    ax[0].plot(x, y, 'r', linewidth=1.5)\n",
    "    x, y = circle_points(blobs2[k,0], blobs2[k,1], 3*np.sqrt(2)*blobs2[k,2])\n",
    "    ax[1].plot(x, y, 'r', linewidth=1.5)\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "13750abc9d12799351ce9969a7699fee",
     "grade": false,
     "grade_id": "cell-c8b0c3c82b968d2e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 3.4 Illustrate detected regions with high overlap\n",
    "\n",
    "In this part, we build on the results from the previous steps. In **Step 3.1**, we matched local features between the two images using OpenCV’s brute-force matcher and stored the corresponding points in `source_pts` and `target_pts`. Using these point correspondences, we apply RANSAC to estimate a similarity transformation (`H1to2p`) between the two images. This transformation captures the relative scale, rotation, and translation.  \n",
    "\n",
    "In **Step 3.2**, blobs were detected independently in both images. Once the transformation is known, the blobs detected in the first image (`blobs1`) can be mapped into the coordinate system of the second image. This produces a transformed set of blobs (`blobs1t`), which can be directly compared with the blobs detected in the second image (`blobs2`). To evaluate the correspondence, we compute a distance matrix `distmat` between every transformed blob and every blob in the second image.  \n",
    "\n",
    "By selecting the nearest neighbors and sorting them by distance, we identify the best correspondences between regions. Finally, we visualize the top matches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "18f84b8f2e8634f735ad7464e5738fe8",
     "grade": false,
     "grade_id": "cell-fd412491f09b94ce",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First, estimate the geometric transformation between images\n",
    "rthrs=10\n",
    "tform,_ = ransac((source_pts, target_pts), SimilarityTransform, min_samples=2,\n",
    "                               residual_threshold=rthrs, max_trials=1000)\n",
    "H1to2p = tform.params\n",
    "s = np.sqrt(np.linalg.det(H1to2p[0:2,0:2]));\n",
    "R = H1to2p[0:2,0:2] / s;\n",
    "t = H1to2p[0:2,2];\n",
    "\n",
    "# Then, detect regions with high overlap\n",
    "xy1to2=s*np.dot(R, blobs1[:,0:2].T)+np.tile(t,(blobs1.shape[0],1)).T\n",
    "blobs1t=np.hstack((xy1to2.T, s*np.expand_dims(blobs1[:,2],axis=1), np.expand_dims(blobs1[:,3], axis=1)))\n",
    "\n",
    "distmat = np.zeros((blobs1.shape[0], blobs2.shape[0]))\n",
    "for i in range(blobs1.shape[0]):\n",
    "    for j in range(blobs2.shape[0]):\n",
    "        distmat[i,j] = np.linalg.norm(blobs1t[i, 0:3] - blobs2[j, 0:3])\n",
    "\n",
    "dist = np.amin(distmat, axis=0)\n",
    "nnids = np.argmin(distmat, axis=0)\n",
    "sdist = np.sort(dist)\n",
    "sids = np.argsort(dist)\n",
    "idlist = np.vstack((nnids[sids], sids, sdist)).T\n",
    "\n",
    "# Visualize the 10 best matches\n",
    "Nvis = 10\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.suptitle(\"Blob detection and matching\", fontsize=20)\n",
    "\n",
    "montage = np.concatenate((img1, img2), axis=1)\n",
    "plt.imshow(montage, cmap='gray')\n",
    "plt.title('Top {} nearest neighbors of blobs features'.format(Nvis))\n",
    "\n",
    "theta = np.arange(0, 2*np.pi+0.1, 0.1)\n",
    "for k in range(Nvis):\n",
    "    loc1 = blobs1[int(idlist[k, 0]), 0:2]\n",
    "    r1 = 3*np.sqrt(2)*blobs1[int(idlist[k,0]), 2]\n",
    "    loc2 = blobs2[int(idlist[k, 1]), 0:2]\n",
    "    r2 = 3*np.sqrt(2)*blobs2[int(idlist[k,1]), 2]\n",
    "    x1 = loc1[0]+r1*np.cos(theta)\n",
    "    y1 = loc1[1]+r1*np.sin(theta)\n",
    "    x2 = loc2[0]+r2*np.cos(theta)+img1.shape[1]\n",
    "    y2 = loc2[1]+r2*np.sin(theta)\n",
    "    plt.plot(x1, y1, 'm-', linewidth=3)\n",
    "    plt.plot(x2, y2, 'm-', linewidth=3)\n",
    "    plt.plot([loc1[0], loc2[0]+img1.shape[1]],[loc1[1], loc2[1]], 'c-')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5439b1b9c5f74b0b073b57fbef940786",
     "grade": false,
     "grade_id": "cell-553cc177477960f3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Exercise 4 - Vectorized pairwise distance computation – DEMO (no points)\n",
    "\n",
    "Exercise 2.2 demonstrated how to compute the pairwise distances of feature vectors to matrix `distmat`, either using a **for-loop implementation** or a **faster vectorized version**. \n",
    "\n",
    "Exercise 4 is a demo showing that the vectorized descriptor matching implementation produces the same results as the standard for-loop approach. This demo is provided for verification purposes only, no points are awarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate random data\n",
    "X = np.random.randn(5, 10)\n",
    "Y = np.random.randn(4, 10)\n",
    "\n",
    "# vectorized\n",
    "distmat = np.dot(X,Y.T)\n",
    "X_terms = np.expand_dims(np.diag(np.dot(X, X.T)), axis=1)\n",
    "X_terms = np.tile(X_terms,(1,4))\n",
    "Y_terms = np.expand_dims(np.diag(np.dot(Y, Y.T)), axis=0)\n",
    "Y_terms = np.tile(Y_terms,(5,1))\n",
    "distmat_vec = np.sqrt(Y_terms + X_terms - 2*distmat)\n",
    "\n",
    "print(f\"distmat by vectorization: \\n {distmat_vec} \\n\")\n",
    "\n",
    "# for-loop\n",
    "distmat_for = np.zeros((X.shape[0], Y.shape[0]))\n",
    "for i in range(X.shape[0]):\n",
    "    for j in range(Y.shape[0]):\n",
    "        distmat_for[i,j] = np.linalg.norm(X[i,:] - Y[j,:])\n",
    "\n",
    "print(f\"distmat by for-loop: \\n {distmat_for} \\n\")\n",
    "\n",
    "print(f\"Difference: {np.sum(distmat_vec-distmat_for)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
